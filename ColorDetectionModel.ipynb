{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   red  green  blue  label\n0   20    139   240   Blue\n1  174     83    72  Brown\n2  144    249   131  Green\n3  168     25   156   Pink\n4   30    182   136  Green",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>red</th>\n      <th>green</th>\n      <th>blue</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>139</td>\n      <td>240</td>\n      <td>Blue</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>174</td>\n      <td>83</td>\n      <td>72</td>\n      <td>Brown</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>144</td>\n      <td>249</td>\n      <td>131</td>\n      <td>Green</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>168</td>\n      <td>25</td>\n      <td>156</td>\n      <td>Pink</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>182</td>\n      <td>136</td>\n      <td>Green</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Dataset.csv')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(5052, 4)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "               red        green         blue\ncount  5052.000000  5052.000000  5052.000000\nmean    127.416073   126.316310   128.296912\nstd      73.958449    74.927131    74.174008\nmin       0.000000     0.000000     0.000000\n25%      63.000000    60.000000    63.000000\n50%     128.000000   127.000000   130.000000\n75%     191.000000   192.000000   192.000000\nmax     255.000000   255.000000   255.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>red</th>\n      <th>green</th>\n      <th>blue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5052.000000</td>\n      <td>5052.000000</td>\n      <td>5052.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>127.416073</td>\n      <td>126.316310</td>\n      <td>128.296912</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>73.958449</td>\n      <td>74.927131</td>\n      <td>74.174008</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>63.000000</td>\n      <td>60.000000</td>\n      <td>63.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>128.000000</td>\n      <td>127.000000</td>\n      <td>130.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>191.000000</td>\n      <td>192.000000</td>\n      <td>192.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5052 entries, 0 to 5051\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   red     5052 non-null   int64 \n",
      " 1   green   5052 non-null   int64 \n",
      " 2   blue    5052 non-null   int64 \n",
      " 3   label   5052 non-null   object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 158.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['label'] = np.array([data['label']]).reshape(-1,1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "data['label'] = labelEncoder.fit_transform(data['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   red  green  blue  label\n0   20    139   240      1\n1  174     83    72      2\n2  144    249   131      3\n3  168     25   156      6\n4   30    182   136      3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>red</th>\n      <th>green</th>\n      <th>blue</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>139</td>\n      <td>240</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>174</td>\n      <td>83</td>\n      <td>72</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>144</td>\n      <td>249</td>\n      <td>131</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>168</td>\n      <td>25</td>\n      <td>156</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>182</td>\n      <td>136</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X = data.drop(columns=['label'])\n",
    "Y= data['label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.2, random_state=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(units=3, input_shape=(3,), activation='relu'),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=11, activation='linear')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               1024      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,903\n",
      "Trainable params: 42,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "51/51 [==============================] - 1s 7ms/step - loss: 1.4710 - accuracy: 0.5371 - val_loss: 1.0464 - val_accuracy: 0.6267\n",
      "Epoch 2/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.0032 - accuracy: 0.6250 - val_loss: 1.0697 - val_accuracy: 0.5649\n",
      "Epoch 3/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.8598 - accuracy: 0.6547 - val_loss: 0.7444 - val_accuracy: 0.6551\n",
      "Epoch 4/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.7666 - accuracy: 0.6804 - val_loss: 0.6645 - val_accuracy: 0.7330\n",
      "Epoch 5/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.7235 - accuracy: 0.6937 - val_loss: 0.7129 - val_accuracy: 0.6848\n",
      "Epoch 6/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.7091 - accuracy: 0.7082 - val_loss: 0.6355 - val_accuracy: 0.7417\n",
      "Epoch 7/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.7074 - accuracy: 0.6968 - val_loss: 0.6132 - val_accuracy: 0.7281\n",
      "Epoch 8/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.7200 - val_loss: 0.5675 - val_accuracy: 0.7614\n",
      "Epoch 9/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7370 - val_loss: 0.5797 - val_accuracy: 0.7454\n",
      "Epoch 10/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.7262 - val_loss: 0.6184 - val_accuracy: 0.7342\n",
      "Epoch 11/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.7283 - val_loss: 0.5903 - val_accuracy: 0.7491\n",
      "Epoch 12/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7475 - val_loss: 0.5638 - val_accuracy: 0.7676\n",
      "Epoch 13/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7556 - val_loss: 0.5685 - val_accuracy: 0.7676\n",
      "Epoch 14/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7546 - val_loss: 0.5067 - val_accuracy: 0.7936\n",
      "Epoch 15/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7664 - val_loss: 0.6605 - val_accuracy: 0.6885\n",
      "Epoch 16/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7540 - val_loss: 0.5655 - val_accuracy: 0.7602\n",
      "Epoch 17/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7522 - val_loss: 0.5069 - val_accuracy: 0.7985\n",
      "Epoch 18/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7686 - val_loss: 0.5234 - val_accuracy: 0.7800\n",
      "Epoch 19/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7636 - val_loss: 0.5351 - val_accuracy: 0.7849\n",
      "Epoch 20/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7614 - val_loss: 0.5079 - val_accuracy: 0.8084\n",
      "Epoch 21/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7701 - val_loss: 0.4841 - val_accuracy: 0.8171\n",
      "Epoch 22/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7754 - val_loss: 0.4788 - val_accuracy: 0.8331\n",
      "Epoch 23/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7828 - val_loss: 0.4761 - val_accuracy: 0.8146\n",
      "Epoch 24/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7754 - val_loss: 0.5653 - val_accuracy: 0.7602\n",
      "Epoch 25/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7831 - val_loss: 0.4969 - val_accuracy: 0.8208\n",
      "Epoch 26/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7874 - val_loss: 0.4805 - val_accuracy: 0.7911\n",
      "Epoch 27/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7908 - val_loss: 0.4744 - val_accuracy: 0.7948\n",
      "Epoch 28/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7847 - val_loss: 0.4569 - val_accuracy: 0.8319\n",
      "Epoch 29/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7921 - val_loss: 0.4639 - val_accuracy: 0.8109\n",
      "Epoch 30/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7958 - val_loss: 0.4467 - val_accuracy: 0.8245\n",
      "Epoch 31/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8066 - val_loss: 0.4379 - val_accuracy: 0.8195\n",
      "Epoch 32/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8011 - val_loss: 0.4776 - val_accuracy: 0.8208\n",
      "Epoch 33/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7915 - val_loss: 0.4526 - val_accuracy: 0.8257\n",
      "Epoch 34/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7983 - val_loss: 0.4571 - val_accuracy: 0.8059\n",
      "Epoch 35/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7970 - val_loss: 0.4706 - val_accuracy: 0.8010\n",
      "Epoch 36/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8082 - val_loss: 0.4911 - val_accuracy: 0.8072\n",
      "Epoch 37/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.8079 - val_loss: 0.4445 - val_accuracy: 0.8257\n",
      "Epoch 38/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8140 - val_loss: 0.4557 - val_accuracy: 0.8208\n",
      "Epoch 39/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8001 - val_loss: 0.4415 - val_accuracy: 0.8220\n",
      "Epoch 40/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8088 - val_loss: 0.4793 - val_accuracy: 0.8010\n",
      "Epoch 41/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.8011 - val_loss: 0.4582 - val_accuracy: 0.8158\n",
      "Epoch 42/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.8060 - val_loss: 0.4235 - val_accuracy: 0.8344\n",
      "Epoch 43/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8168 - val_loss: 0.4744 - val_accuracy: 0.7985\n",
      "Epoch 44/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8122 - val_loss: 0.4119 - val_accuracy: 0.8307\n",
      "Epoch 45/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8147 - val_loss: 0.4234 - val_accuracy: 0.8517\n",
      "Epoch 46/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.8168 - val_loss: 0.4232 - val_accuracy: 0.8294\n",
      "Epoch 47/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8085 - val_loss: 0.4184 - val_accuracy: 0.8368\n",
      "Epoch 48/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8274 - val_loss: 0.4256 - val_accuracy: 0.8418\n",
      "Epoch 49/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8267 - val_loss: 0.4278 - val_accuracy: 0.8257\n",
      "Epoch 50/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8202 - val_loss: 0.4115 - val_accuracy: 0.8307\n",
      "Epoch 51/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8301 - val_loss: 0.4231 - val_accuracy: 0.8331\n",
      "Epoch 52/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8205 - val_loss: 0.4107 - val_accuracy: 0.8331\n",
      "Epoch 53/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.8215 - val_loss: 0.4446 - val_accuracy: 0.8146\n",
      "Epoch 54/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8137 - val_loss: 0.4030 - val_accuracy: 0.8381\n",
      "Epoch 55/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8317 - val_loss: 0.3949 - val_accuracy: 0.8381\n",
      "Epoch 56/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8280 - val_loss: 0.4192 - val_accuracy: 0.8245\n",
      "Epoch 57/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8212 - val_loss: 0.4212 - val_accuracy: 0.8220\n",
      "Epoch 58/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8270 - val_loss: 0.3973 - val_accuracy: 0.8467\n",
      "Epoch 59/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8363 - val_loss: 0.4171 - val_accuracy: 0.8307\n",
      "Epoch 60/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8258 - val_loss: 0.3946 - val_accuracy: 0.8344\n",
      "Epoch 61/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8329 - val_loss: 0.3899 - val_accuracy: 0.8405\n",
      "Epoch 62/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8249 - val_loss: 0.4118 - val_accuracy: 0.8344\n",
      "Epoch 63/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8369 - val_loss: 0.4143 - val_accuracy: 0.8344\n",
      "Epoch 64/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8286 - val_loss: 0.4142 - val_accuracy: 0.8368\n",
      "Epoch 65/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8335 - val_loss: 0.4082 - val_accuracy: 0.8381\n",
      "Epoch 66/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8289 - val_loss: 0.3868 - val_accuracy: 0.8578\n",
      "Epoch 67/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8385 - val_loss: 0.3884 - val_accuracy: 0.8480\n",
      "Epoch 68/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8292 - val_loss: 0.4113 - val_accuracy: 0.8282\n",
      "Epoch 69/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8323 - val_loss: 0.3942 - val_accuracy: 0.8294\n",
      "Epoch 70/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8397 - val_loss: 0.3761 - val_accuracy: 0.8381\n",
      "Epoch 71/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8342 - val_loss: 0.3926 - val_accuracy: 0.8467\n",
      "Epoch 72/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8410 - val_loss: 0.3687 - val_accuracy: 0.8480\n",
      "Epoch 73/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8379 - val_loss: 0.3828 - val_accuracy: 0.8430\n",
      "Epoch 74/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8403 - val_loss: 0.4113 - val_accuracy: 0.8220\n",
      "Epoch 75/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8366 - val_loss: 0.4095 - val_accuracy: 0.8294\n",
      "Epoch 76/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8456 - val_loss: 0.3958 - val_accuracy: 0.8356\n",
      "Epoch 77/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8475 - val_loss: 0.4169 - val_accuracy: 0.8294\n",
      "Epoch 78/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8416 - val_loss: 0.3850 - val_accuracy: 0.8504\n",
      "Epoch 79/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8342 - val_loss: 0.3848 - val_accuracy: 0.8356\n",
      "Epoch 80/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8499 - val_loss: 0.4306 - val_accuracy: 0.8133\n",
      "Epoch 81/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8360 - val_loss: 0.3956 - val_accuracy: 0.8282\n",
      "Epoch 82/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8329 - val_loss: 0.3953 - val_accuracy: 0.8393\n",
      "Epoch 83/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8425 - val_loss: 0.3968 - val_accuracy: 0.8554\n",
      "Epoch 84/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8465 - val_loss: 0.3973 - val_accuracy: 0.8245\n",
      "Epoch 85/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8490 - val_loss: 0.3850 - val_accuracy: 0.8418\n",
      "Epoch 86/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8478 - val_loss: 0.3769 - val_accuracy: 0.8492\n",
      "Epoch 87/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8434 - val_loss: 0.4026 - val_accuracy: 0.8529\n",
      "Epoch 88/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8295 - val_loss: 0.4088 - val_accuracy: 0.8443\n",
      "Epoch 89/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8413 - val_loss: 0.3847 - val_accuracy: 0.8480\n",
      "Epoch 90/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8428 - val_loss: 0.4311 - val_accuracy: 0.8294\n",
      "Epoch 91/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8416 - val_loss: 0.3960 - val_accuracy: 0.8405\n",
      "Epoch 92/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8478 - val_loss: 0.4044 - val_accuracy: 0.8381\n",
      "Epoch 93/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8456 - val_loss: 0.4183 - val_accuracy: 0.8257\n",
      "Epoch 94/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8366 - val_loss: 0.4018 - val_accuracy: 0.8443\n",
      "Epoch 95/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8524 - val_loss: 0.3883 - val_accuracy: 0.8418\n",
      "Epoch 96/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8407 - val_loss: 0.4103 - val_accuracy: 0.8418\n",
      "Epoch 97/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8475 - val_loss: 0.4140 - val_accuracy: 0.8282\n",
      "Epoch 98/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8478 - val_loss: 0.3958 - val_accuracy: 0.8381\n",
      "Epoch 99/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8468 - val_loss: 0.4045 - val_accuracy: 0.8504\n",
      "Epoch 100/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8428 - val_loss: 0.3917 - val_accuracy: 0.8418\n",
      "Epoch 101/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8403 - val_loss: 0.3969 - val_accuracy: 0.8492\n",
      "Epoch 102/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8410 - val_loss: 0.4055 - val_accuracy: 0.8381\n",
      "Epoch 103/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8357 - val_loss: 0.3878 - val_accuracy: 0.8455\n",
      "Epoch 104/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8438 - val_loss: 0.4221 - val_accuracy: 0.8381\n",
      "Epoch 105/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8475 - val_loss: 0.4209 - val_accuracy: 0.8331\n",
      "Epoch 106/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8506 - val_loss: 0.3931 - val_accuracy: 0.8344\n",
      "Epoch 107/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8487 - val_loss: 0.3965 - val_accuracy: 0.8492\n",
      "Epoch 108/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8481 - val_loss: 0.5222 - val_accuracy: 0.8084\n",
      "Epoch 109/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8385 - val_loss: 0.4230 - val_accuracy: 0.8171\n",
      "Epoch 110/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8564 - val_loss: 0.3996 - val_accuracy: 0.8455\n",
      "Epoch 111/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8422 - val_loss: 0.4090 - val_accuracy: 0.8418\n",
      "Epoch 112/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8502 - val_loss: 0.4075 - val_accuracy: 0.8232\n",
      "Epoch 113/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8490 - val_loss: 0.4192 - val_accuracy: 0.8319\n",
      "Epoch 114/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8255 - val_loss: 0.3839 - val_accuracy: 0.8467\n",
      "Epoch 115/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8456 - val_loss: 0.4192 - val_accuracy: 0.8356\n",
      "Epoch 116/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8561 - val_loss: 0.4147 - val_accuracy: 0.8344\n",
      "Epoch 117/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8419 - val_loss: 0.4024 - val_accuracy: 0.8504\n",
      "Epoch 118/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8468 - val_loss: 0.4318 - val_accuracy: 0.8257\n",
      "Epoch 119/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8481 - val_loss: 0.4002 - val_accuracy: 0.8393\n",
      "Epoch 120/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8546 - val_loss: 0.3992 - val_accuracy: 0.8418\n",
      "Epoch 121/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8481 - val_loss: 0.3966 - val_accuracy: 0.8344\n",
      "Epoch 122/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8524 - val_loss: 0.4082 - val_accuracy: 0.8344\n",
      "Epoch 123/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8496 - val_loss: 0.3976 - val_accuracy: 0.8405\n",
      "Epoch 124/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8561 - val_loss: 0.4094 - val_accuracy: 0.8356\n",
      "Epoch 125/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8502 - val_loss: 0.4060 - val_accuracy: 0.8405\n",
      "Epoch 126/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8512 - val_loss: 0.3808 - val_accuracy: 0.8529\n",
      "Epoch 127/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8533 - val_loss: 0.4333 - val_accuracy: 0.8368\n",
      "Epoch 128/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8512 - val_loss: 0.4015 - val_accuracy: 0.8381\n",
      "Epoch 129/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8543 - val_loss: 0.4584 - val_accuracy: 0.8232\n",
      "Epoch 130/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8552 - val_loss: 0.3817 - val_accuracy: 0.8640\n",
      "Epoch 131/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8527 - val_loss: 0.4153 - val_accuracy: 0.8368\n",
      "Epoch 132/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8527 - val_loss: 0.4024 - val_accuracy: 0.8455\n",
      "Epoch 133/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8558 - val_loss: 0.4179 - val_accuracy: 0.8405\n",
      "Epoch 134/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8487 - val_loss: 0.4110 - val_accuracy: 0.8381\n",
      "Epoch 135/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8450 - val_loss: 0.3958 - val_accuracy: 0.8467\n",
      "Epoch 136/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.8530 - val_loss: 0.3985 - val_accuracy: 0.8344\n",
      "Epoch 137/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8441 - val_loss: 0.3925 - val_accuracy: 0.8393\n",
      "Epoch 138/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8543 - val_loss: 0.3969 - val_accuracy: 0.8405\n",
      "Epoch 139/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8629 - val_loss: 0.4305 - val_accuracy: 0.8331\n",
      "Epoch 140/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8589 - val_loss: 0.4016 - val_accuracy: 0.8467\n",
      "Epoch 141/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8459 - val_loss: 0.3974 - val_accuracy: 0.8455\n",
      "Epoch 142/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8490 - val_loss: 0.3968 - val_accuracy: 0.8430\n",
      "Epoch 143/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8549 - val_loss: 0.4339 - val_accuracy: 0.8381\n",
      "Epoch 144/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8490 - val_loss: 0.4095 - val_accuracy: 0.8467\n",
      "Epoch 145/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8487 - val_loss: 0.4166 - val_accuracy: 0.8467\n",
      "Epoch 146/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8493 - val_loss: 0.4075 - val_accuracy: 0.8467\n",
      "Epoch 147/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8608 - val_loss: 0.4068 - val_accuracy: 0.8430\n",
      "Epoch 148/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8608 - val_loss: 0.4420 - val_accuracy: 0.8368\n",
      "Epoch 149/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8481 - val_loss: 0.4032 - val_accuracy: 0.8405\n",
      "Epoch 150/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8549 - val_loss: 0.4070 - val_accuracy: 0.8381\n",
      "Epoch 151/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8475 - val_loss: 0.4371 - val_accuracy: 0.8257\n",
      "Epoch 152/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8465 - val_loss: 0.3909 - val_accuracy: 0.8529\n",
      "Epoch 153/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8648 - val_loss: 0.4335 - val_accuracy: 0.8331\n",
      "Epoch 154/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8623 - val_loss: 0.4376 - val_accuracy: 0.8344\n",
      "Epoch 155/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8558 - val_loss: 0.4229 - val_accuracy: 0.8492\n",
      "Epoch 156/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8540 - val_loss: 0.4153 - val_accuracy: 0.8368\n",
      "Epoch 157/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8543 - val_loss: 0.4067 - val_accuracy: 0.8430\n",
      "Epoch 158/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8608 - val_loss: 0.4109 - val_accuracy: 0.8368\n",
      "Epoch 159/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8524 - val_loss: 0.4405 - val_accuracy: 0.8282\n",
      "Epoch 160/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8546 - val_loss: 0.4222 - val_accuracy: 0.8393\n",
      "Epoch 161/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8537 - val_loss: 0.4849 - val_accuracy: 0.8208\n",
      "Epoch 162/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8580 - val_loss: 0.4163 - val_accuracy: 0.8368\n",
      "Epoch 163/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8629 - val_loss: 0.4166 - val_accuracy: 0.8368\n",
      "Epoch 164/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8632 - val_loss: 0.4151 - val_accuracy: 0.8492\n",
      "Epoch 165/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8577 - val_loss: 0.3989 - val_accuracy: 0.8430\n",
      "Epoch 166/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8459 - val_loss: 0.3958 - val_accuracy: 0.8480\n",
      "Epoch 167/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8598 - val_loss: 0.4573 - val_accuracy: 0.8232\n",
      "Epoch 168/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8518 - val_loss: 0.4233 - val_accuracy: 0.8381\n",
      "Epoch 169/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8552 - val_loss: 0.4247 - val_accuracy: 0.8393\n",
      "Epoch 170/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8552 - val_loss: 0.4273 - val_accuracy: 0.8443\n",
      "Epoch 171/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8617 - val_loss: 0.4227 - val_accuracy: 0.8480\n",
      "Epoch 172/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8614 - val_loss: 0.4014 - val_accuracy: 0.8480\n",
      "Epoch 173/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8586 - val_loss: 0.4178 - val_accuracy: 0.8294\n",
      "Epoch 174/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8583 - val_loss: 0.4238 - val_accuracy: 0.8418\n",
      "Epoch 175/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8468 - val_loss: 0.4163 - val_accuracy: 0.8480\n",
      "Epoch 176/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8462 - val_loss: 0.4035 - val_accuracy: 0.8504\n",
      "Epoch 177/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8589 - val_loss: 0.3975 - val_accuracy: 0.8368\n",
      "Epoch 178/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8611 - val_loss: 0.4101 - val_accuracy: 0.8443\n",
      "Epoch 179/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8518 - val_loss: 0.4381 - val_accuracy: 0.8443\n",
      "Epoch 180/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8512 - val_loss: 0.4082 - val_accuracy: 0.8368\n",
      "Epoch 181/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8608 - val_loss: 0.4193 - val_accuracy: 0.8381\n",
      "Epoch 182/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8592 - val_loss: 0.3936 - val_accuracy: 0.8566\n",
      "Epoch 183/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8620 - val_loss: 0.4505 - val_accuracy: 0.8356\n",
      "Epoch 184/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8626 - val_loss: 0.3977 - val_accuracy: 0.8430\n",
      "Epoch 185/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8617 - val_loss: 0.4184 - val_accuracy: 0.8368\n",
      "Epoch 186/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8583 - val_loss: 0.4115 - val_accuracy: 0.8430\n",
      "Epoch 187/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8484 - val_loss: 0.4142 - val_accuracy: 0.8554\n",
      "Epoch 188/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8601 - val_loss: 0.4243 - val_accuracy: 0.8455\n",
      "Epoch 189/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8543 - val_loss: 0.4372 - val_accuracy: 0.8393\n",
      "Epoch 190/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8676 - val_loss: 0.4223 - val_accuracy: 0.8368\n",
      "Epoch 191/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8580 - val_loss: 0.4392 - val_accuracy: 0.8430\n",
      "Epoch 192/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8676 - val_loss: 0.4343 - val_accuracy: 0.8405\n",
      "Epoch 193/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8654 - val_loss: 0.4149 - val_accuracy: 0.8418\n",
      "Epoch 194/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8623 - val_loss: 0.4152 - val_accuracy: 0.8393\n",
      "Epoch 195/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8527 - val_loss: 0.4120 - val_accuracy: 0.8430\n",
      "Epoch 196/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8608 - val_loss: 0.3875 - val_accuracy: 0.8504\n",
      "Epoch 197/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8620 - val_loss: 0.4392 - val_accuracy: 0.8356\n",
      "Epoch 198/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8512 - val_loss: 0.4088 - val_accuracy: 0.8455\n",
      "Epoch 199/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8657 - val_loss: 0.4300 - val_accuracy: 0.8455\n",
      "Epoch 200/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8521 - val_loss: 0.4390 - val_accuracy: 0.8282\n",
      "Epoch 201/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8592 - val_loss: 0.4010 - val_accuracy: 0.8480\n",
      "Epoch 202/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8651 - val_loss: 0.4025 - val_accuracy: 0.8430\n",
      "Epoch 203/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8623 - val_loss: 0.4149 - val_accuracy: 0.8443\n",
      "Epoch 204/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8617 - val_loss: 0.4301 - val_accuracy: 0.8455\n",
      "Epoch 205/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8577 - val_loss: 0.4104 - val_accuracy: 0.8504\n",
      "Epoch 206/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8642 - val_loss: 0.4196 - val_accuracy: 0.8405\n",
      "Epoch 207/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8623 - val_loss: 0.4386 - val_accuracy: 0.8282\n",
      "Epoch 208/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8564 - val_loss: 0.4067 - val_accuracy: 0.8418\n",
      "Epoch 209/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8598 - val_loss: 0.4152 - val_accuracy: 0.8368\n",
      "Epoch 210/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8605 - val_loss: 0.4379 - val_accuracy: 0.8418\n",
      "Epoch 211/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8601 - val_loss: 0.4210 - val_accuracy: 0.8405\n",
      "Epoch 212/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8645 - val_loss: 0.4286 - val_accuracy: 0.8492\n",
      "Epoch 213/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8629 - val_loss: 0.4311 - val_accuracy: 0.8344\n",
      "Epoch 214/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8626 - val_loss: 0.4330 - val_accuracy: 0.8344\n",
      "Epoch 215/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8555 - val_loss: 0.4146 - val_accuracy: 0.8467\n",
      "Epoch 216/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8567 - val_loss: 0.4373 - val_accuracy: 0.8418\n",
      "Epoch 217/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8676 - val_loss: 0.4219 - val_accuracy: 0.8331\n",
      "Epoch 218/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8617 - val_loss: 0.4298 - val_accuracy: 0.8331\n",
      "Epoch 219/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8654 - val_loss: 0.4124 - val_accuracy: 0.8455\n",
      "Epoch 220/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8608 - val_loss: 0.4597 - val_accuracy: 0.8257\n",
      "Epoch 221/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8673 - val_loss: 0.4188 - val_accuracy: 0.8430\n",
      "Epoch 222/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8583 - val_loss: 0.4461 - val_accuracy: 0.8282\n",
      "Epoch 223/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8626 - val_loss: 0.4809 - val_accuracy: 0.8319\n",
      "Epoch 224/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8608 - val_loss: 0.4472 - val_accuracy: 0.8504\n",
      "Epoch 225/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8614 - val_loss: 0.4202 - val_accuracy: 0.8455\n",
      "Epoch 226/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8614 - val_loss: 0.4406 - val_accuracy: 0.8405\n",
      "Epoch 227/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8626 - val_loss: 0.4219 - val_accuracy: 0.8480\n",
      "Epoch 228/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8608 - val_loss: 0.4369 - val_accuracy: 0.8368\n",
      "Epoch 229/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8670 - val_loss: 0.4673 - val_accuracy: 0.8294\n",
      "Epoch 230/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8595 - val_loss: 0.4190 - val_accuracy: 0.8541\n",
      "Epoch 231/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8666 - val_loss: 0.4648 - val_accuracy: 0.8405\n",
      "Epoch 232/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8512 - val_loss: 0.4138 - val_accuracy: 0.8492\n",
      "Epoch 233/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8663 - val_loss: 0.4166 - val_accuracy: 0.8504\n",
      "Epoch 234/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8577 - val_loss: 0.4340 - val_accuracy: 0.8467\n",
      "Epoch 235/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8586 - val_loss: 0.4140 - val_accuracy: 0.8430\n",
      "Epoch 236/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3128 - accuracy: 0.8694 - val_loss: 0.4314 - val_accuracy: 0.8443\n",
      "Epoch 237/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8645 - val_loss: 0.4040 - val_accuracy: 0.8603\n",
      "Epoch 238/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8645 - val_loss: 0.4161 - val_accuracy: 0.8480\n",
      "Epoch 239/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8639 - val_loss: 0.4310 - val_accuracy: 0.8344\n",
      "Epoch 240/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3194 - accuracy: 0.8629 - val_loss: 0.4066 - val_accuracy: 0.8455\n",
      "Epoch 241/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3218 - accuracy: 0.8629 - val_loss: 0.4114 - val_accuracy: 0.8467\n",
      "Epoch 242/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8679 - val_loss: 0.4592 - val_accuracy: 0.8356\n",
      "Epoch 243/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8645 - val_loss: 0.4076 - val_accuracy: 0.8492\n",
      "Epoch 244/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8673 - val_loss: 0.4156 - val_accuracy: 0.8492\n",
      "Epoch 245/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.8673 - val_loss: 0.4363 - val_accuracy: 0.8492\n",
      "Epoch 246/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8605 - val_loss: 0.4195 - val_accuracy: 0.8418\n",
      "Epoch 247/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8691 - val_loss: 0.4293 - val_accuracy: 0.8430\n",
      "Epoch 248/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8694 - val_loss: 0.4045 - val_accuracy: 0.8529\n",
      "Epoch 249/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8670 - val_loss: 0.4769 - val_accuracy: 0.8418\n",
      "Epoch 250/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8642 - val_loss: 0.4434 - val_accuracy: 0.8480\n",
      "Epoch 251/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8657 - val_loss: 0.4342 - val_accuracy: 0.8541\n",
      "Epoch 252/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8700 - val_loss: 0.4437 - val_accuracy: 0.8517\n",
      "Epoch 253/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8688 - val_loss: 0.4611 - val_accuracy: 0.8517\n",
      "Epoch 254/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8586 - val_loss: 0.4407 - val_accuracy: 0.8480\n",
      "Epoch 255/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8676 - val_loss: 0.4561 - val_accuracy: 0.8368\n",
      "Epoch 256/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3125 - accuracy: 0.8657 - val_loss: 0.4097 - val_accuracy: 0.8492\n",
      "Epoch 257/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8747 - val_loss: 0.4381 - val_accuracy: 0.8467\n",
      "Epoch 258/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8670 - val_loss: 0.4454 - val_accuracy: 0.8430\n",
      "Epoch 259/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8670 - val_loss: 0.4040 - val_accuracy: 0.8480\n",
      "Epoch 260/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8639 - val_loss: 0.4417 - val_accuracy: 0.8492\n",
      "Epoch 261/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8673 - val_loss: 0.4386 - val_accuracy: 0.8405\n",
      "Epoch 262/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8567 - val_loss: 0.4348 - val_accuracy: 0.8405\n",
      "Epoch 263/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8719 - val_loss: 0.4308 - val_accuracy: 0.8356\n",
      "Epoch 264/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8697 - val_loss: 0.4529 - val_accuracy: 0.8368\n",
      "Epoch 265/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8660 - val_loss: 0.4241 - val_accuracy: 0.8443\n",
      "Epoch 266/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8626 - val_loss: 0.4328 - val_accuracy: 0.8504\n",
      "Epoch 267/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8657 - val_loss: 0.4371 - val_accuracy: 0.8405\n",
      "Epoch 268/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8728 - val_loss: 0.4449 - val_accuracy: 0.8331\n",
      "Epoch 269/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8731 - val_loss: 0.4291 - val_accuracy: 0.8480\n",
      "Epoch 270/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8660 - val_loss: 0.4085 - val_accuracy: 0.8566\n",
      "Epoch 271/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8670 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 272/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8707 - val_loss: 0.4204 - val_accuracy: 0.8418\n",
      "Epoch 273/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8642 - val_loss: 0.4450 - val_accuracy: 0.8393\n",
      "Epoch 274/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8688 - val_loss: 0.4297 - val_accuracy: 0.8443\n",
      "Epoch 275/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8676 - val_loss: 0.4347 - val_accuracy: 0.8381\n",
      "Epoch 276/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8632 - val_loss: 0.4541 - val_accuracy: 0.8331\n",
      "Epoch 277/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8663 - val_loss: 0.4438 - val_accuracy: 0.8393\n",
      "Epoch 278/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8632 - val_loss: 0.4748 - val_accuracy: 0.8307\n",
      "Epoch 279/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8614 - val_loss: 0.4628 - val_accuracy: 0.8467\n",
      "Epoch 280/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8700 - val_loss: 0.4407 - val_accuracy: 0.8430\n",
      "Epoch 281/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8663 - val_loss: 0.4277 - val_accuracy: 0.8443\n",
      "Epoch 282/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.8716 - val_loss: 0.4397 - val_accuracy: 0.8443\n",
      "Epoch 283/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8778 - val_loss: 0.4211 - val_accuracy: 0.8517\n",
      "Epoch 284/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8666 - val_loss: 0.4520 - val_accuracy: 0.8430\n",
      "Epoch 285/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8719 - val_loss: 0.4762 - val_accuracy: 0.8443\n",
      "Epoch 286/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3068 - accuracy: 0.8679 - val_loss: 0.4534 - val_accuracy: 0.8381\n",
      "Epoch 287/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8738 - val_loss: 0.4435 - val_accuracy: 0.8430\n",
      "Epoch 288/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8676 - val_loss: 0.4559 - val_accuracy: 0.8356\n",
      "Epoch 289/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8666 - val_loss: 0.4349 - val_accuracy: 0.8443\n",
      "Epoch 290/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.8759 - val_loss: 0.4297 - val_accuracy: 0.8492\n",
      "Epoch 291/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3049 - accuracy: 0.8697 - val_loss: 0.4455 - val_accuracy: 0.8443\n",
      "Epoch 292/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8719 - val_loss: 0.4446 - val_accuracy: 0.8418\n",
      "Epoch 293/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8728 - val_loss: 0.4280 - val_accuracy: 0.8492\n",
      "Epoch 294/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8747 - val_loss: 0.4353 - val_accuracy: 0.8405\n",
      "Epoch 295/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8713 - val_loss: 0.4268 - val_accuracy: 0.8443\n",
      "Epoch 296/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8691 - val_loss: 0.4219 - val_accuracy: 0.8480\n",
      "Epoch 297/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8747 - val_loss: 0.4384 - val_accuracy: 0.8492\n",
      "Epoch 298/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.8778 - val_loss: 0.4466 - val_accuracy: 0.8405\n",
      "Epoch 299/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8772 - val_loss: 0.4461 - val_accuracy: 0.8418\n",
      "Epoch 300/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2898 - accuracy: 0.8809 - val_loss: 0.4372 - val_accuracy: 0.8368\n",
      "Epoch 301/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8722 - val_loss: 0.4099 - val_accuracy: 0.8430\n",
      "Epoch 302/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8697 - val_loss: 0.4472 - val_accuracy: 0.8467\n",
      "Epoch 303/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8700 - val_loss: 0.4604 - val_accuracy: 0.8331\n",
      "Epoch 304/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8725 - val_loss: 0.4644 - val_accuracy: 0.8381\n",
      "Epoch 305/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8676 - val_loss: 0.4181 - val_accuracy: 0.8492\n",
      "Epoch 306/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8651 - val_loss: 0.4564 - val_accuracy: 0.8430\n",
      "Epoch 307/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8685 - val_loss: 0.4440 - val_accuracy: 0.8467\n",
      "Epoch 308/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8713 - val_loss: 0.4307 - val_accuracy: 0.8467\n",
      "Epoch 309/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8744 - val_loss: 0.4463 - val_accuracy: 0.8443\n",
      "Epoch 310/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8750 - val_loss: 0.4323 - val_accuracy: 0.8504\n",
      "Epoch 311/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8744 - val_loss: 0.4639 - val_accuracy: 0.8405\n",
      "Epoch 312/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8728 - val_loss: 0.4523 - val_accuracy: 0.8294\n",
      "Epoch 313/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8660 - val_loss: 0.4359 - val_accuracy: 0.8480\n",
      "Epoch 314/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8663 - val_loss: 0.4286 - val_accuracy: 0.8418\n",
      "Epoch 315/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2913 - accuracy: 0.8790 - val_loss: 0.4240 - val_accuracy: 0.8480\n",
      "Epoch 316/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8812 - val_loss: 0.4151 - val_accuracy: 0.8578\n",
      "Epoch 317/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8731 - val_loss: 0.4253 - val_accuracy: 0.8405\n",
      "Epoch 318/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8670 - val_loss: 0.4620 - val_accuracy: 0.8467\n",
      "Epoch 319/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8744 - val_loss: 0.4742 - val_accuracy: 0.8430\n",
      "Epoch 320/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8759 - val_loss: 0.4446 - val_accuracy: 0.8344\n",
      "Epoch 321/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8759 - val_loss: 0.4692 - val_accuracy: 0.8381\n",
      "Epoch 322/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8728 - val_loss: 0.4189 - val_accuracy: 0.8504\n",
      "Epoch 323/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2932 - accuracy: 0.8744 - val_loss: 0.5436 - val_accuracy: 0.8171\n",
      "Epoch 324/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.8716 - val_loss: 0.4406 - val_accuracy: 0.8492\n",
      "Epoch 325/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.8725 - val_loss: 0.4674 - val_accuracy: 0.8455\n",
      "Epoch 326/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.8803 - val_loss: 0.4935 - val_accuracy: 0.8418\n",
      "Epoch 327/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.8765 - val_loss: 0.4520 - val_accuracy: 0.8418\n",
      "Epoch 328/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8716 - val_loss: 0.4412 - val_accuracy: 0.8504\n",
      "Epoch 329/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8750 - val_loss: 0.4553 - val_accuracy: 0.8504\n",
      "Epoch 330/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.8759 - val_loss: 0.4606 - val_accuracy: 0.8368\n",
      "Epoch 331/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8710 - val_loss: 0.4365 - val_accuracy: 0.8467\n",
      "Epoch 332/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8784 - val_loss: 0.4575 - val_accuracy: 0.8418\n",
      "Epoch 333/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8803 - val_loss: 0.4679 - val_accuracy: 0.8381\n",
      "Epoch 334/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.8744 - val_loss: 0.4433 - val_accuracy: 0.8467\n",
      "Epoch 335/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8784 - val_loss: 0.4364 - val_accuracy: 0.8443\n",
      "Epoch 336/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8719 - val_loss: 0.4408 - val_accuracy: 0.8356\n",
      "Epoch 337/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8784 - val_loss: 0.4554 - val_accuracy: 0.8405\n",
      "Epoch 338/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8765 - val_loss: 0.4842 - val_accuracy: 0.8405\n",
      "Epoch 339/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8784 - val_loss: 0.4235 - val_accuracy: 0.8443\n",
      "Epoch 340/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8775 - val_loss: 0.4657 - val_accuracy: 0.8443\n",
      "Epoch 341/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8697 - val_loss: 0.4809 - val_accuracy: 0.8344\n",
      "Epoch 342/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8697 - val_loss: 0.4769 - val_accuracy: 0.8356\n",
      "Epoch 343/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8738 - val_loss: 0.4372 - val_accuracy: 0.8517\n",
      "Epoch 344/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3108 - accuracy: 0.8697 - val_loss: 0.4648 - val_accuracy: 0.8418\n",
      "Epoch 345/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8744 - val_loss: 0.4477 - val_accuracy: 0.8443\n",
      "Epoch 346/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2859 - accuracy: 0.8762 - val_loss: 0.4820 - val_accuracy: 0.8331\n",
      "Epoch 347/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8731 - val_loss: 0.4338 - val_accuracy: 0.8418\n",
      "Epoch 348/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8713 - val_loss: 0.4557 - val_accuracy: 0.8418\n",
      "Epoch 349/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8713 - val_loss: 0.4995 - val_accuracy: 0.8245\n",
      "Epoch 350/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8719 - val_loss: 0.4263 - val_accuracy: 0.8430\n",
      "Epoch 351/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8679 - val_loss: 0.4380 - val_accuracy: 0.8517\n",
      "Epoch 352/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2864 - accuracy: 0.8750 - val_loss: 0.4496 - val_accuracy: 0.8381\n",
      "Epoch 353/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8781 - val_loss: 0.4596 - val_accuracy: 0.8430\n",
      "Epoch 354/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8806 - val_loss: 0.4559 - val_accuracy: 0.8467\n",
      "Epoch 355/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.8793 - val_loss: 0.4427 - val_accuracy: 0.8443\n",
      "Epoch 356/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2817 - accuracy: 0.8790 - val_loss: 0.4254 - val_accuracy: 0.8492\n",
      "Epoch 357/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.8750 - val_loss: 0.4656 - val_accuracy: 0.8443\n",
      "Epoch 358/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.8765 - val_loss: 0.4516 - val_accuracy: 0.8405\n",
      "Epoch 359/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8787 - val_loss: 0.4694 - val_accuracy: 0.8393\n",
      "Epoch 360/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8704 - val_loss: 0.4253 - val_accuracy: 0.8480\n",
      "Epoch 361/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8735 - val_loss: 0.4636 - val_accuracy: 0.8492\n",
      "Epoch 362/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8728 - val_loss: 0.4429 - val_accuracy: 0.8418\n",
      "Epoch 363/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8793 - val_loss: 0.4254 - val_accuracy: 0.8480\n",
      "Epoch 364/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8756 - val_loss: 0.4595 - val_accuracy: 0.8467\n",
      "Epoch 365/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8725 - val_loss: 0.4485 - val_accuracy: 0.8430\n",
      "Epoch 366/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8747 - val_loss: 0.4423 - val_accuracy: 0.8467\n",
      "Epoch 367/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.8769 - val_loss: 0.4734 - val_accuracy: 0.8368\n",
      "Epoch 368/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.8756 - val_loss: 0.4979 - val_accuracy: 0.8418\n",
      "Epoch 369/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8762 - val_loss: 0.4450 - val_accuracy: 0.8554\n",
      "Epoch 370/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8759 - val_loss: 0.4538 - val_accuracy: 0.8443\n",
      "Epoch 371/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8830 - val_loss: 0.4599 - val_accuracy: 0.8480\n",
      "Epoch 372/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8759 - val_loss: 0.4681 - val_accuracy: 0.8368\n",
      "Epoch 373/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2821 - accuracy: 0.8809 - val_loss: 0.4418 - val_accuracy: 0.8455\n",
      "Epoch 374/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.8731 - val_loss: 0.4317 - val_accuracy: 0.8480\n",
      "Epoch 375/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.8753 - val_loss: 0.4894 - val_accuracy: 0.8381\n",
      "Epoch 376/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8809 - val_loss: 0.4571 - val_accuracy: 0.8467\n",
      "Epoch 377/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8815 - val_loss: 0.4483 - val_accuracy: 0.8467\n",
      "Epoch 378/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8769 - val_loss: 0.4569 - val_accuracy: 0.8430\n",
      "Epoch 379/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.8815 - val_loss: 0.4895 - val_accuracy: 0.8368\n",
      "Epoch 380/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8750 - val_loss: 0.4464 - val_accuracy: 0.8430\n",
      "Epoch 381/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8796 - val_loss: 0.4810 - val_accuracy: 0.8443\n",
      "Epoch 382/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8809 - val_loss: 0.4701 - val_accuracy: 0.8529\n",
      "Epoch 383/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2953 - accuracy: 0.8728 - val_loss: 0.5009 - val_accuracy: 0.8356\n",
      "Epoch 384/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2937 - accuracy: 0.8673 - val_loss: 0.4523 - val_accuracy: 0.8467\n",
      "Epoch 385/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8753 - val_loss: 0.4724 - val_accuracy: 0.8492\n",
      "Epoch 386/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.8796 - val_loss: 0.4686 - val_accuracy: 0.8455\n",
      "Epoch 387/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.8837 - val_loss: 0.4683 - val_accuracy: 0.8344\n",
      "Epoch 388/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8830 - val_loss: 0.4336 - val_accuracy: 0.8566\n",
      "Epoch 389/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8738 - val_loss: 0.4566 - val_accuracy: 0.8393\n",
      "Epoch 390/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2901 - accuracy: 0.8784 - val_loss: 0.4696 - val_accuracy: 0.8331\n",
      "Epoch 391/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2769 - accuracy: 0.8809 - val_loss: 0.4495 - val_accuracy: 0.8430\n",
      "Epoch 392/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2874 - accuracy: 0.8744 - val_loss: 0.4858 - val_accuracy: 0.8418\n",
      "Epoch 393/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2863 - accuracy: 0.8784 - val_loss: 0.4364 - val_accuracy: 0.8492\n",
      "Epoch 394/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2853 - accuracy: 0.8827 - val_loss: 0.4793 - val_accuracy: 0.8405\n",
      "Epoch 395/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2863 - accuracy: 0.8744 - val_loss: 0.4634 - val_accuracy: 0.8344\n",
      "Epoch 396/1000\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.2793 - accuracy: 0.8818 - val_loss: 0.4889 - val_accuracy: 0.8430\n",
      "Epoch 397/1000\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.2799 - accuracy: 0.8778 - val_loss: 0.4837 - val_accuracy: 0.8405\n",
      "Epoch 398/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2888 - accuracy: 0.8793 - val_loss: 0.4769 - val_accuracy: 0.8480\n",
      "Epoch 399/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8821 - val_loss: 0.4626 - val_accuracy: 0.8418\n",
      "Epoch 400/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8796 - val_loss: 0.4596 - val_accuracy: 0.8443\n",
      "Epoch 401/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8784 - val_loss: 0.4496 - val_accuracy: 0.8504\n",
      "Epoch 402/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8812 - val_loss: 0.4445 - val_accuracy: 0.8541\n",
      "Epoch 403/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2735 - accuracy: 0.8846 - val_loss: 0.4623 - val_accuracy: 0.8467\n",
      "Epoch 404/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8790 - val_loss: 0.4581 - val_accuracy: 0.8430\n",
      "Epoch 405/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8837 - val_loss: 0.4340 - val_accuracy: 0.8492\n",
      "Epoch 406/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.8827 - val_loss: 0.4750 - val_accuracy: 0.8455\n",
      "Epoch 407/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2670 - accuracy: 0.8880 - val_loss: 0.5006 - val_accuracy: 0.8455\n",
      "Epoch 408/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8803 - val_loss: 0.4911 - val_accuracy: 0.8405\n",
      "Epoch 409/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8874 - val_loss: 0.4982 - val_accuracy: 0.8443\n",
      "Epoch 410/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8809 - val_loss: 0.4761 - val_accuracy: 0.8418\n",
      "Epoch 411/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8803 - val_loss: 0.4811 - val_accuracy: 0.8405\n",
      "Epoch 412/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.8716 - val_loss: 0.4849 - val_accuracy: 0.8282\n",
      "Epoch 413/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2839 - accuracy: 0.8821 - val_loss: 0.4617 - val_accuracy: 0.8430\n",
      "Epoch 414/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8654 - val_loss: 0.4628 - val_accuracy: 0.8467\n",
      "Epoch 415/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8704 - val_loss: 0.4421 - val_accuracy: 0.8504\n",
      "Epoch 416/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 0.8781 - val_loss: 0.4797 - val_accuracy: 0.8368\n",
      "Epoch 417/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8769 - val_loss: 0.5227 - val_accuracy: 0.8319\n",
      "Epoch 418/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8765 - val_loss: 0.4907 - val_accuracy: 0.8455\n",
      "Epoch 419/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8818 - val_loss: 0.4789 - val_accuracy: 0.8368\n",
      "Epoch 420/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8790 - val_loss: 0.4679 - val_accuracy: 0.8418\n",
      "Epoch 421/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8871 - val_loss: 0.4579 - val_accuracy: 0.8430\n",
      "Epoch 422/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8815 - val_loss: 0.4947 - val_accuracy: 0.8319\n",
      "Epoch 423/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.8775 - val_loss: 0.4763 - val_accuracy: 0.8381\n",
      "Epoch 424/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8738 - val_loss: 0.4651 - val_accuracy: 0.8492\n",
      "Epoch 425/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.8790 - val_loss: 0.5060 - val_accuracy: 0.8393\n",
      "Epoch 426/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8775 - val_loss: 0.4519 - val_accuracy: 0.8430\n",
      "Epoch 427/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8809 - val_loss: 0.4690 - val_accuracy: 0.8331\n",
      "Epoch 428/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2740 - accuracy: 0.8772 - val_loss: 0.4744 - val_accuracy: 0.8467\n",
      "Epoch 429/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8843 - val_loss: 0.4595 - val_accuracy: 0.8443\n",
      "Epoch 430/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8812 - val_loss: 0.5108 - val_accuracy: 0.8393\n",
      "Epoch 431/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.8871 - val_loss: 0.4660 - val_accuracy: 0.8467\n",
      "Epoch 432/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.8824 - val_loss: 0.4791 - val_accuracy: 0.8405\n",
      "Epoch 433/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8843 - val_loss: 0.4698 - val_accuracy: 0.8467\n",
      "Epoch 434/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.8769 - val_loss: 0.5072 - val_accuracy: 0.8443\n",
      "Epoch 435/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2712 - accuracy: 0.8846 - val_loss: 0.4843 - val_accuracy: 0.8418\n",
      "Epoch 436/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.8790 - val_loss: 0.4994 - val_accuracy: 0.8331\n",
      "Epoch 437/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8793 - val_loss: 0.4452 - val_accuracy: 0.8455\n",
      "Epoch 438/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8790 - val_loss: 0.4812 - val_accuracy: 0.8517\n",
      "Epoch 439/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8812 - val_loss: 0.4625 - val_accuracy: 0.8344\n",
      "Epoch 440/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8815 - val_loss: 0.4774 - val_accuracy: 0.8381\n",
      "Epoch 441/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8818 - val_loss: 0.4705 - val_accuracy: 0.8418\n",
      "Epoch 442/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.8868 - val_loss: 0.4961 - val_accuracy: 0.8455\n",
      "Epoch 443/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.8800 - val_loss: 0.4759 - val_accuracy: 0.8405\n",
      "Epoch 444/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8945 - val_loss: 0.4598 - val_accuracy: 0.8492\n",
      "Epoch 445/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8784 - val_loss: 0.5116 - val_accuracy: 0.8331\n",
      "Epoch 446/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8803 - val_loss: 0.5266 - val_accuracy: 0.8467\n",
      "Epoch 447/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8818 - val_loss: 0.5017 - val_accuracy: 0.8418\n",
      "Epoch 448/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8892 - val_loss: 0.4780 - val_accuracy: 0.8443\n",
      "Epoch 449/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8880 - val_loss: 0.4756 - val_accuracy: 0.8356\n",
      "Epoch 450/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8741 - val_loss: 0.4903 - val_accuracy: 0.8331\n",
      "Epoch 451/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8852 - val_loss: 0.4926 - val_accuracy: 0.8368\n",
      "Epoch 452/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8781 - val_loss: 0.4915 - val_accuracy: 0.8443\n",
      "Epoch 453/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8800 - val_loss: 0.5215 - val_accuracy: 0.8393\n",
      "Epoch 454/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8821 - val_loss: 0.4582 - val_accuracy: 0.8467\n",
      "Epoch 455/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.8840 - val_loss: 0.4765 - val_accuracy: 0.8467\n",
      "Epoch 456/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.8899 - val_loss: 0.5216 - val_accuracy: 0.8331\n",
      "Epoch 457/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8806 - val_loss: 0.5047 - val_accuracy: 0.8443\n",
      "Epoch 458/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.8735 - val_loss: 0.4983 - val_accuracy: 0.8381\n",
      "Epoch 459/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8800 - val_loss: 0.5554 - val_accuracy: 0.8294\n",
      "Epoch 460/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.8868 - val_loss: 0.4819 - val_accuracy: 0.8529\n",
      "Epoch 461/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8827 - val_loss: 0.4612 - val_accuracy: 0.8467\n",
      "Epoch 462/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8840 - val_loss: 0.4768 - val_accuracy: 0.8480\n",
      "Epoch 463/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8846 - val_loss: 0.5246 - val_accuracy: 0.8344\n",
      "Epoch 464/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8880 - val_loss: 0.4658 - val_accuracy: 0.8504\n",
      "Epoch 465/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8837 - val_loss: 0.4800 - val_accuracy: 0.8418\n",
      "Epoch 466/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8840 - val_loss: 0.4736 - val_accuracy: 0.8541\n",
      "Epoch 467/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8818 - val_loss: 0.4876 - val_accuracy: 0.8405\n",
      "Epoch 468/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.8824 - val_loss: 0.5416 - val_accuracy: 0.8381\n",
      "Epoch 469/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.8815 - val_loss: 0.4500 - val_accuracy: 0.8492\n",
      "Epoch 470/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8827 - val_loss: 0.4658 - val_accuracy: 0.8418\n",
      "Epoch 471/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8800 - val_loss: 0.4986 - val_accuracy: 0.8455\n",
      "Epoch 472/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.8796 - val_loss: 0.5228 - val_accuracy: 0.8331\n",
      "Epoch 473/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.8858 - val_loss: 0.4868 - val_accuracy: 0.8492\n",
      "Epoch 474/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.8908 - val_loss: 0.4753 - val_accuracy: 0.8430\n",
      "Epoch 475/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8877 - val_loss: 0.4677 - val_accuracy: 0.8492\n",
      "Epoch 476/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2717 - accuracy: 0.8827 - val_loss: 0.5036 - val_accuracy: 0.8480\n",
      "Epoch 477/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.8858 - val_loss: 0.5493 - val_accuracy: 0.8307\n",
      "Epoch 478/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8694 - val_loss: 0.4737 - val_accuracy: 0.8492\n",
      "Epoch 479/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.8899 - val_loss: 0.5489 - val_accuracy: 0.8381\n",
      "Epoch 480/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8787 - val_loss: 0.4740 - val_accuracy: 0.8455\n",
      "Epoch 481/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2692 - accuracy: 0.8871 - val_loss: 0.4802 - val_accuracy: 0.8430\n",
      "Epoch 482/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8772 - val_loss: 0.5009 - val_accuracy: 0.8504\n",
      "Epoch 483/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.8812 - val_loss: 0.5113 - val_accuracy: 0.8344\n",
      "Epoch 484/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8800 - val_loss: 0.5194 - val_accuracy: 0.8331\n",
      "Epoch 485/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8846 - val_loss: 0.5345 - val_accuracy: 0.8455\n",
      "Epoch 486/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8861 - val_loss: 0.5056 - val_accuracy: 0.8405\n",
      "Epoch 487/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2573 - accuracy: 0.8877 - val_loss: 0.4737 - val_accuracy: 0.8529\n",
      "Epoch 488/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.8939 - val_loss: 0.4977 - val_accuracy: 0.8393\n",
      "Epoch 489/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2560 - accuracy: 0.8936 - val_loss: 0.5120 - val_accuracy: 0.8393\n",
      "Epoch 490/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8877 - val_loss: 0.5228 - val_accuracy: 0.8455\n",
      "Epoch 491/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.8858 - val_loss: 0.5398 - val_accuracy: 0.8405\n",
      "Epoch 492/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8849 - val_loss: 0.5173 - val_accuracy: 0.8381\n",
      "Epoch 493/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8871 - val_loss: 0.5649 - val_accuracy: 0.8393\n",
      "Epoch 494/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.8843 - val_loss: 0.5150 - val_accuracy: 0.8294\n",
      "Epoch 495/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.8864 - val_loss: 0.5228 - val_accuracy: 0.8393\n",
      "Epoch 496/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.8883 - val_loss: 0.5459 - val_accuracy: 0.8381\n",
      "Epoch 497/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.8840 - val_loss: 0.5250 - val_accuracy: 0.8405\n",
      "Epoch 498/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8883 - val_loss: 0.5649 - val_accuracy: 0.8368\n",
      "Epoch 499/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8834 - val_loss: 0.4882 - val_accuracy: 0.8467\n",
      "Epoch 500/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8818 - val_loss: 0.4567 - val_accuracy: 0.8455\n",
      "Epoch 501/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8673 - val_loss: 0.5139 - val_accuracy: 0.8393\n",
      "Epoch 502/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8741 - val_loss: 0.4966 - val_accuracy: 0.8443\n",
      "Epoch 503/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.8936 - val_loss: 0.5192 - val_accuracy: 0.8393\n",
      "Epoch 504/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8871 - val_loss: 0.5288 - val_accuracy: 0.8331\n",
      "Epoch 505/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8793 - val_loss: 0.5343 - val_accuracy: 0.8356\n",
      "Epoch 506/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.8843 - val_loss: 0.4811 - val_accuracy: 0.8467\n",
      "Epoch 507/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.8929 - val_loss: 0.4923 - val_accuracy: 0.8504\n",
      "Epoch 508/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.8852 - val_loss: 0.4672 - val_accuracy: 0.8554\n",
      "Epoch 509/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.8883 - val_loss: 0.5237 - val_accuracy: 0.8455\n",
      "Epoch 510/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2588 - accuracy: 0.8846 - val_loss: 0.5197 - val_accuracy: 0.8492\n",
      "Epoch 511/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.8902 - val_loss: 0.4913 - val_accuracy: 0.8443\n",
      "Epoch 512/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8852 - val_loss: 0.5094 - val_accuracy: 0.8381\n",
      "Epoch 513/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.8793 - val_loss: 0.4934 - val_accuracy: 0.8368\n",
      "Epoch 514/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8880 - val_loss: 0.4823 - val_accuracy: 0.8492\n",
      "Epoch 515/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8877 - val_loss: 0.4724 - val_accuracy: 0.8566\n",
      "Epoch 516/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.8939 - val_loss: 0.4978 - val_accuracy: 0.8443\n",
      "Epoch 517/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8868 - val_loss: 0.5495 - val_accuracy: 0.8368\n",
      "Epoch 518/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8855 - val_loss: 0.5190 - val_accuracy: 0.8418\n",
      "Epoch 519/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.8855 - val_loss: 0.5256 - val_accuracy: 0.8344\n",
      "Epoch 520/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8840 - val_loss: 0.5243 - val_accuracy: 0.8418\n",
      "Epoch 521/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8812 - val_loss: 0.5417 - val_accuracy: 0.8356\n",
      "Epoch 522/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8880 - val_loss: 0.4954 - val_accuracy: 0.8517\n",
      "Epoch 523/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8843 - val_loss: 0.5155 - val_accuracy: 0.8344\n",
      "Epoch 524/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8815 - val_loss: 0.5411 - val_accuracy: 0.8319\n",
      "Epoch 525/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.8871 - val_loss: 0.4993 - val_accuracy: 0.8356\n",
      "Epoch 526/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8871 - val_loss: 0.5368 - val_accuracy: 0.8430\n",
      "Epoch 527/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8855 - val_loss: 0.5209 - val_accuracy: 0.8331\n",
      "Epoch 528/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8827 - val_loss: 0.4907 - val_accuracy: 0.8405\n",
      "Epoch 529/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8855 - val_loss: 0.4856 - val_accuracy: 0.8418\n",
      "Epoch 530/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8840 - val_loss: 0.4883 - val_accuracy: 0.8356\n",
      "Epoch 531/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.8874 - val_loss: 0.4732 - val_accuracy: 0.8480\n",
      "Epoch 532/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8877 - val_loss: 0.5711 - val_accuracy: 0.8393\n",
      "Epoch 533/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8747 - val_loss: 0.5008 - val_accuracy: 0.8331\n",
      "Epoch 534/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8846 - val_loss: 0.5149 - val_accuracy: 0.8443\n",
      "Epoch 535/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8753 - val_loss: 0.5430 - val_accuracy: 0.8331\n",
      "Epoch 536/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8843 - val_loss: 0.4926 - val_accuracy: 0.8368\n",
      "Epoch 537/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8892 - val_loss: 0.4960 - val_accuracy: 0.8455\n",
      "Epoch 538/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.8843 - val_loss: 0.5074 - val_accuracy: 0.8405\n",
      "Epoch 539/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2590 - accuracy: 0.8849 - val_loss: 0.5111 - val_accuracy: 0.8418\n",
      "Epoch 540/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.8812 - val_loss: 0.5178 - val_accuracy: 0.8455\n",
      "Epoch 541/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2522 - accuracy: 0.8914 - val_loss: 0.5465 - val_accuracy: 0.8331\n",
      "Epoch 542/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2581 - accuracy: 0.8877 - val_loss: 0.5209 - val_accuracy: 0.8368\n",
      "Epoch 543/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8846 - val_loss: 0.5558 - val_accuracy: 0.8418\n",
      "Epoch 544/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8731 - val_loss: 0.5094 - val_accuracy: 0.8467\n",
      "Epoch 545/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.8861 - val_loss: 0.5128 - val_accuracy: 0.8356\n",
      "Epoch 546/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.8880 - val_loss: 0.4822 - val_accuracy: 0.8467\n",
      "Epoch 547/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8917 - val_loss: 0.5303 - val_accuracy: 0.8368\n",
      "Epoch 548/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.8883 - val_loss: 0.5123 - val_accuracy: 0.8393\n",
      "Epoch 549/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2634 - accuracy: 0.8874 - val_loss: 0.5066 - val_accuracy: 0.8356\n",
      "Epoch 550/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.8868 - val_loss: 0.5329 - val_accuracy: 0.8443\n",
      "Epoch 551/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.8929 - val_loss: 0.5121 - val_accuracy: 0.8381\n",
      "Epoch 552/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.8871 - val_loss: 0.4937 - val_accuracy: 0.8356\n",
      "Epoch 553/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.8899 - val_loss: 0.5078 - val_accuracy: 0.8492\n",
      "Epoch 554/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2560 - accuracy: 0.8908 - val_loss: 0.4959 - val_accuracy: 0.8467\n",
      "Epoch 555/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8821 - val_loss: 0.5206 - val_accuracy: 0.8356\n",
      "Epoch 556/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.8864 - val_loss: 0.5125 - val_accuracy: 0.8517\n",
      "Epoch 557/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.8963 - val_loss: 0.5266 - val_accuracy: 0.8418\n",
      "Epoch 558/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.8864 - val_loss: 0.5765 - val_accuracy: 0.8344\n",
      "Epoch 559/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.8871 - val_loss: 0.5046 - val_accuracy: 0.8443\n",
      "Epoch 560/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8889 - val_loss: 0.4957 - val_accuracy: 0.8405\n",
      "Epoch 561/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.8855 - val_loss: 0.5290 - val_accuracy: 0.8455\n",
      "Epoch 562/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.8902 - val_loss: 0.4945 - val_accuracy: 0.8467\n",
      "Epoch 563/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8855 - val_loss: 0.4914 - val_accuracy: 0.8331\n",
      "Epoch 564/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8812 - val_loss: 0.5430 - val_accuracy: 0.8356\n",
      "Epoch 565/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.8880 - val_loss: 0.5153 - val_accuracy: 0.8443\n",
      "Epoch 566/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8827 - val_loss: 0.5260 - val_accuracy: 0.8393\n",
      "Epoch 567/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.8877 - val_loss: 0.5056 - val_accuracy: 0.8356\n",
      "Epoch 568/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8855 - val_loss: 0.5351 - val_accuracy: 0.8344\n",
      "Epoch 569/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.8895 - val_loss: 0.5326 - val_accuracy: 0.8504\n",
      "Epoch 570/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8923 - val_loss: 0.4752 - val_accuracy: 0.8405\n",
      "Epoch 571/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8914 - val_loss: 0.5365 - val_accuracy: 0.8492\n",
      "Epoch 572/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.8939 - val_loss: 0.5556 - val_accuracy: 0.8405\n",
      "Epoch 573/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8874 - val_loss: 0.5123 - val_accuracy: 0.8430\n",
      "Epoch 574/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8886 - val_loss: 0.4823 - val_accuracy: 0.8467\n",
      "Epoch 575/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8877 - val_loss: 0.5085 - val_accuracy: 0.8467\n",
      "Epoch 576/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8939 - val_loss: 0.5166 - val_accuracy: 0.8282\n",
      "Epoch 577/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.8772 - val_loss: 0.5031 - val_accuracy: 0.8405\n",
      "Epoch 578/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.8889 - val_loss: 0.5300 - val_accuracy: 0.8405\n",
      "Epoch 579/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8908 - val_loss: 0.5359 - val_accuracy: 0.8405\n",
      "Epoch 580/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8942 - val_loss: 0.5091 - val_accuracy: 0.8430\n",
      "Epoch 581/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2544 - accuracy: 0.8889 - val_loss: 0.5388 - val_accuracy: 0.8356\n",
      "Epoch 582/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.8902 - val_loss: 0.5279 - val_accuracy: 0.8331\n",
      "Epoch 583/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.8855 - val_loss: 0.4943 - val_accuracy: 0.8368\n",
      "Epoch 584/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8756 - val_loss: 0.5707 - val_accuracy: 0.8307\n",
      "Epoch 585/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8753 - val_loss: 0.5177 - val_accuracy: 0.8381\n",
      "Epoch 586/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8673 - val_loss: 0.5088 - val_accuracy: 0.8381\n",
      "Epoch 587/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.8855 - val_loss: 0.4872 - val_accuracy: 0.8492\n",
      "Epoch 588/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.8871 - val_loss: 0.5117 - val_accuracy: 0.8455\n",
      "Epoch 589/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8926 - val_loss: 0.5068 - val_accuracy: 0.8418\n",
      "Epoch 590/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.8880 - val_loss: 0.4647 - val_accuracy: 0.8554\n",
      "Epoch 591/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8765 - val_loss: 0.5204 - val_accuracy: 0.8405\n",
      "Epoch 592/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.8905 - val_loss: 0.4971 - val_accuracy: 0.8467\n",
      "Epoch 593/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2595 - accuracy: 0.8874 - val_loss: 0.5275 - val_accuracy: 0.8492\n",
      "Epoch 594/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.8871 - val_loss: 0.5327 - val_accuracy: 0.8381\n",
      "Epoch 595/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.8883 - val_loss: 0.5353 - val_accuracy: 0.8467\n",
      "Epoch 596/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.8920 - val_loss: 0.5134 - val_accuracy: 0.8418\n",
      "Epoch 597/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.8917 - val_loss: 0.5547 - val_accuracy: 0.8430\n",
      "Epoch 598/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.8936 - val_loss: 0.5278 - val_accuracy: 0.8405\n",
      "Epoch 599/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.8852 - val_loss: 0.4922 - val_accuracy: 0.8393\n",
      "Epoch 600/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.8849 - val_loss: 0.5730 - val_accuracy: 0.8455\n",
      "Epoch 601/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2431 - accuracy: 0.8948 - val_loss: 0.5387 - val_accuracy: 0.8467\n",
      "Epoch 602/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.8908 - val_loss: 0.5555 - val_accuracy: 0.8443\n",
      "Epoch 603/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.8892 - val_loss: 0.5237 - val_accuracy: 0.8455\n",
      "Epoch 604/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2690 - accuracy: 0.8827 - val_loss: 0.5092 - val_accuracy: 0.8393\n",
      "Epoch 605/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.8917 - val_loss: 0.5128 - val_accuracy: 0.8443\n",
      "Epoch 606/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.8908 - val_loss: 0.5749 - val_accuracy: 0.8344\n",
      "Epoch 607/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.8936 - val_loss: 0.5555 - val_accuracy: 0.8405\n",
      "Epoch 608/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.8911 - val_loss: 0.5190 - val_accuracy: 0.8368\n",
      "Epoch 609/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.8871 - val_loss: 0.5206 - val_accuracy: 0.8455\n",
      "Epoch 610/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.8929 - val_loss: 0.5022 - val_accuracy: 0.8405\n",
      "Epoch 611/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8837 - val_loss: 0.5636 - val_accuracy: 0.8405\n",
      "Epoch 612/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8846 - val_loss: 0.5308 - val_accuracy: 0.8368\n",
      "Epoch 613/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.8902 - val_loss: 0.5672 - val_accuracy: 0.8319\n",
      "Epoch 614/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.8858 - val_loss: 0.5153 - val_accuracy: 0.8430\n",
      "Epoch 615/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.8926 - val_loss: 0.5429 - val_accuracy: 0.8405\n",
      "Epoch 616/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.8868 - val_loss: 0.4959 - val_accuracy: 0.8480\n",
      "Epoch 617/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8716 - val_loss: 0.5566 - val_accuracy: 0.8356\n",
      "Epoch 618/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.8803 - val_loss: 0.5908 - val_accuracy: 0.8455\n",
      "Epoch 619/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8911 - val_loss: 0.5581 - val_accuracy: 0.8430\n",
      "Epoch 620/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.8868 - val_loss: 0.5456 - val_accuracy: 0.8430\n",
      "Epoch 621/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8849 - val_loss: 0.5509 - val_accuracy: 0.8381\n",
      "Epoch 622/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.8911 - val_loss: 0.5477 - val_accuracy: 0.8282\n",
      "Epoch 623/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.8917 - val_loss: 0.5131 - val_accuracy: 0.8418\n",
      "Epoch 624/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.8908 - val_loss: 0.5464 - val_accuracy: 0.8344\n",
      "Epoch 625/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8858 - val_loss: 0.5119 - val_accuracy: 0.8381\n",
      "Epoch 626/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.8899 - val_loss: 0.5514 - val_accuracy: 0.8430\n",
      "Epoch 627/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8824 - val_loss: 0.5089 - val_accuracy: 0.8344\n",
      "Epoch 628/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8716 - val_loss: 0.4854 - val_accuracy: 0.8381\n",
      "Epoch 629/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8843 - val_loss: 0.5330 - val_accuracy: 0.8381\n",
      "Epoch 630/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8858 - val_loss: 0.5024 - val_accuracy: 0.8381\n",
      "Epoch 631/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.8942 - val_loss: 0.5327 - val_accuracy: 0.8356\n",
      "Epoch 632/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8917 - val_loss: 0.5187 - val_accuracy: 0.8455\n",
      "Epoch 633/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8917 - val_loss: 0.5369 - val_accuracy: 0.8443\n",
      "Epoch 634/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8840 - val_loss: 0.5504 - val_accuracy: 0.8405\n",
      "Epoch 635/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8864 - val_loss: 0.5316 - val_accuracy: 0.8418\n",
      "Epoch 636/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8886 - val_loss: 0.5322 - val_accuracy: 0.8480\n",
      "Epoch 637/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.8905 - val_loss: 0.5367 - val_accuracy: 0.8455\n",
      "Epoch 638/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.8957 - val_loss: 0.5288 - val_accuracy: 0.8455\n",
      "Epoch 639/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.8926 - val_loss: 0.5551 - val_accuracy: 0.8344\n",
      "Epoch 640/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8883 - val_loss: 0.5357 - val_accuracy: 0.8418\n",
      "Epoch 641/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.8899 - val_loss: 0.5322 - val_accuracy: 0.8467\n",
      "Epoch 642/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.8886 - val_loss: 0.5228 - val_accuracy: 0.8405\n",
      "Epoch 643/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2371 - accuracy: 0.8954 - val_loss: 0.5576 - val_accuracy: 0.8443\n",
      "Epoch 644/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2424 - accuracy: 0.8948 - val_loss: 0.5579 - val_accuracy: 0.8443\n",
      "Epoch 645/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2636 - accuracy: 0.8824 - val_loss: 0.5730 - val_accuracy: 0.8455\n",
      "Epoch 646/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.8846 - val_loss: 0.5594 - val_accuracy: 0.8418\n",
      "Epoch 647/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.8917 - val_loss: 0.5787 - val_accuracy: 0.8356\n",
      "Epoch 648/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.8926 - val_loss: 0.5285 - val_accuracy: 0.8443\n",
      "Epoch 649/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.8908 - val_loss: 0.5441 - val_accuracy: 0.8405\n",
      "Epoch 650/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.8954 - val_loss: 0.5491 - val_accuracy: 0.8467\n",
      "Epoch 651/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.8911 - val_loss: 0.5176 - val_accuracy: 0.8393\n",
      "Epoch 652/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.8889 - val_loss: 0.5671 - val_accuracy: 0.8430\n",
      "Epoch 653/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.8883 - val_loss: 0.5744 - val_accuracy: 0.8307\n",
      "Epoch 654/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8837 - val_loss: 0.5300 - val_accuracy: 0.8393\n",
      "Epoch 655/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8846 - val_loss: 0.5494 - val_accuracy: 0.8319\n",
      "Epoch 656/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.8871 - val_loss: 0.5325 - val_accuracy: 0.8307\n",
      "Epoch 657/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.8905 - val_loss: 0.5758 - val_accuracy: 0.8344\n",
      "Epoch 658/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.8911 - val_loss: 0.5141 - val_accuracy: 0.8418\n",
      "Epoch 659/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.8889 - val_loss: 0.5136 - val_accuracy: 0.8405\n",
      "Epoch 660/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.8957 - val_loss: 0.5597 - val_accuracy: 0.8356\n",
      "Epoch 661/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.8951 - val_loss: 0.5408 - val_accuracy: 0.8381\n",
      "Epoch 662/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.8945 - val_loss: 0.5754 - val_accuracy: 0.8504\n",
      "Epoch 663/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.8933 - val_loss: 0.5853 - val_accuracy: 0.8319\n",
      "Epoch 664/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.8939 - val_loss: 0.5952 - val_accuracy: 0.8356\n",
      "Epoch 665/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2538 - accuracy: 0.8892 - val_loss: 0.5730 - val_accuracy: 0.8418\n",
      "Epoch 666/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8840 - val_loss: 0.5214 - val_accuracy: 0.8418\n",
      "Epoch 667/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.8871 - val_loss: 0.5212 - val_accuracy: 0.8381\n",
      "Epoch 668/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8827 - val_loss: 0.5328 - val_accuracy: 0.8455\n",
      "Epoch 669/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.8861 - val_loss: 0.5704 - val_accuracy: 0.8393\n",
      "Epoch 670/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.8892 - val_loss: 0.5745 - val_accuracy: 0.8282\n",
      "Epoch 671/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.8960 - val_loss: 0.5341 - val_accuracy: 0.8467\n",
      "Epoch 672/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.8954 - val_loss: 0.5420 - val_accuracy: 0.8455\n",
      "Epoch 673/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.8929 - val_loss: 0.5566 - val_accuracy: 0.8418\n",
      "Epoch 674/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8880 - val_loss: 0.5473 - val_accuracy: 0.8492\n",
      "Epoch 675/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.8889 - val_loss: 0.5855 - val_accuracy: 0.8319\n",
      "Epoch 676/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8861 - val_loss: 0.5905 - val_accuracy: 0.8368\n",
      "Epoch 677/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.8852 - val_loss: 0.5169 - val_accuracy: 0.8405\n",
      "Epoch 678/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8843 - val_loss: 0.5822 - val_accuracy: 0.8195\n",
      "Epoch 679/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8809 - val_loss: 0.5019 - val_accuracy: 0.8480\n",
      "Epoch 680/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.8985 - val_loss: 0.5527 - val_accuracy: 0.8368\n",
      "Epoch 681/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.8855 - val_loss: 0.5462 - val_accuracy: 0.8418\n",
      "Epoch 682/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.8877 - val_loss: 0.5314 - val_accuracy: 0.8443\n",
      "Epoch 683/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.8855 - val_loss: 0.5827 - val_accuracy: 0.8443\n",
      "Epoch 684/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8800 - val_loss: 0.5451 - val_accuracy: 0.8344\n",
      "Epoch 685/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.8868 - val_loss: 0.5312 - val_accuracy: 0.8393\n",
      "Epoch 686/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.8880 - val_loss: 0.5523 - val_accuracy: 0.8405\n",
      "Epoch 687/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8920 - val_loss: 0.5380 - val_accuracy: 0.8393\n",
      "Epoch 688/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.8976 - val_loss: 0.5474 - val_accuracy: 0.8368\n",
      "Epoch 689/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.8917 - val_loss: 0.5646 - val_accuracy: 0.8443\n",
      "Epoch 690/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.8936 - val_loss: 0.5907 - val_accuracy: 0.8356\n",
      "Epoch 691/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8864 - val_loss: 0.5656 - val_accuracy: 0.8344\n",
      "Epoch 692/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2665 - accuracy: 0.8864 - val_loss: 0.5578 - val_accuracy: 0.8344\n",
      "Epoch 693/1000\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.2454 - accuracy: 0.8936 - val_loss: 0.5461 - val_accuracy: 0.8405\n",
      "Epoch 694/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2441 - accuracy: 0.8926 - val_loss: 0.5338 - val_accuracy: 0.8356\n",
      "Epoch 695/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2393 - accuracy: 0.8967 - val_loss: 0.5604 - val_accuracy: 0.8405\n",
      "Epoch 696/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2482 - accuracy: 0.8914 - val_loss: 0.5517 - val_accuracy: 0.8368\n",
      "Epoch 697/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.8886 - val_loss: 0.6004 - val_accuracy: 0.8344\n",
      "Epoch 698/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2605 - accuracy: 0.8868 - val_loss: 0.5390 - val_accuracy: 0.8368\n",
      "Epoch 699/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.8809 - val_loss: 0.5388 - val_accuracy: 0.8467\n",
      "Epoch 700/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.8880 - val_loss: 0.5475 - val_accuracy: 0.8319\n",
      "Epoch 701/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2538 - accuracy: 0.8874 - val_loss: 0.5956 - val_accuracy: 0.8381\n",
      "Epoch 702/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2583 - accuracy: 0.8852 - val_loss: 0.5441 - val_accuracy: 0.8480\n",
      "Epoch 703/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.8982 - val_loss: 0.5606 - val_accuracy: 0.8418\n",
      "Epoch 704/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2442 - accuracy: 0.8973 - val_loss: 0.5580 - val_accuracy: 0.8467\n",
      "Epoch 705/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2551 - accuracy: 0.8880 - val_loss: 0.5096 - val_accuracy: 0.8492\n",
      "Epoch 706/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2410 - accuracy: 0.8979 - val_loss: 0.5399 - val_accuracy: 0.8430\n",
      "Epoch 707/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2545 - accuracy: 0.8837 - val_loss: 0.5661 - val_accuracy: 0.8307\n",
      "Epoch 708/1000\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.2513 - accuracy: 0.8895 - val_loss: 0.5945 - val_accuracy: 0.8381\n",
      "Epoch 709/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.8970 - val_loss: 0.5631 - val_accuracy: 0.8455\n",
      "Epoch 710/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2421 - accuracy: 0.8942 - val_loss: 0.5337 - val_accuracy: 0.8467\n",
      "Epoch 711/1000\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.2431 - accuracy: 0.8911 - val_loss: 0.5870 - val_accuracy: 0.8381\n",
      "Epoch 712/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2352 - accuracy: 0.8998 - val_loss: 0.5241 - val_accuracy: 0.8455\n",
      "Epoch 713/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8880 - val_loss: 0.5685 - val_accuracy: 0.8492\n",
      "Epoch 714/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.8926 - val_loss: 0.5864 - val_accuracy: 0.8368\n",
      "Epoch 715/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2457 - accuracy: 0.8905 - val_loss: 0.5782 - val_accuracy: 0.8455\n",
      "Epoch 716/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2641 - accuracy: 0.8821 - val_loss: 0.5836 - val_accuracy: 0.8405\n",
      "Epoch 717/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2535 - accuracy: 0.8895 - val_loss: 0.5663 - val_accuracy: 0.8344\n",
      "Epoch 718/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2603 - accuracy: 0.8861 - val_loss: 0.5582 - val_accuracy: 0.8368\n",
      "Epoch 719/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2541 - accuracy: 0.8917 - val_loss: 0.5565 - val_accuracy: 0.8393\n",
      "Epoch 720/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2470 - accuracy: 0.8948 - val_loss: 0.5522 - val_accuracy: 0.8405\n",
      "Epoch 721/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2396 - accuracy: 0.8936 - val_loss: 0.6184 - val_accuracy: 0.8307\n",
      "Epoch 722/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2670 - accuracy: 0.8815 - val_loss: 0.5621 - val_accuracy: 0.8430\n",
      "Epoch 723/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.8874 - val_loss: 0.6030 - val_accuracy: 0.8368\n",
      "Epoch 724/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2532 - accuracy: 0.8892 - val_loss: 0.5793 - val_accuracy: 0.8381\n",
      "Epoch 725/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2531 - accuracy: 0.8902 - val_loss: 0.5585 - val_accuracy: 0.8393\n",
      "Epoch 726/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.8936 - val_loss: 0.5476 - val_accuracy: 0.8443\n",
      "Epoch 727/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2385 - accuracy: 0.8973 - val_loss: 0.5519 - val_accuracy: 0.8381\n",
      "Epoch 728/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2422 - accuracy: 0.8929 - val_loss: 0.5765 - val_accuracy: 0.8418\n",
      "Epoch 729/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2409 - accuracy: 0.8929 - val_loss: 0.5397 - val_accuracy: 0.8405\n",
      "Epoch 730/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9010 - val_loss: 0.5869 - val_accuracy: 0.8331\n",
      "Epoch 731/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2364 - accuracy: 0.8979 - val_loss: 0.5847 - val_accuracy: 0.8443\n",
      "Epoch 732/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.8905 - val_loss: 0.5699 - val_accuracy: 0.8381\n",
      "Epoch 733/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2570 - accuracy: 0.8871 - val_loss: 0.5825 - val_accuracy: 0.8418\n",
      "Epoch 734/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.8871 - val_loss: 0.5557 - val_accuracy: 0.8393\n",
      "Epoch 735/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2437 - accuracy: 0.8945 - val_loss: 0.5688 - val_accuracy: 0.8393\n",
      "Epoch 736/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2330 - accuracy: 0.8998 - val_loss: 0.5728 - val_accuracy: 0.8467\n",
      "Epoch 737/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.8960 - val_loss: 0.5739 - val_accuracy: 0.8319\n",
      "Epoch 738/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2452 - accuracy: 0.8905 - val_loss: 0.5927 - val_accuracy: 0.8368\n",
      "Epoch 739/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2512 - accuracy: 0.8886 - val_loss: 0.5776 - val_accuracy: 0.8344\n",
      "Epoch 740/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.8976 - val_loss: 0.5926 - val_accuracy: 0.8331\n",
      "Epoch 741/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2476 - accuracy: 0.8902 - val_loss: 0.5793 - val_accuracy: 0.8430\n",
      "Epoch 742/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8864 - val_loss: 0.5792 - val_accuracy: 0.8294\n",
      "Epoch 743/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.8926 - val_loss: 0.5417 - val_accuracy: 0.8443\n",
      "Epoch 744/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2357 - accuracy: 0.8945 - val_loss: 0.5807 - val_accuracy: 0.8418\n",
      "Epoch 745/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2350 - accuracy: 0.9001 - val_loss: 0.5878 - val_accuracy: 0.8319\n",
      "Epoch 746/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.8920 - val_loss: 0.5981 - val_accuracy: 0.8381\n",
      "Epoch 747/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.8951 - val_loss: 0.5528 - val_accuracy: 0.8455\n",
      "Epoch 748/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2446 - accuracy: 0.8914 - val_loss: 0.5823 - val_accuracy: 0.8418\n",
      "Epoch 749/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2452 - accuracy: 0.8920 - val_loss: 0.5716 - val_accuracy: 0.8381\n",
      "Epoch 750/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2453 - accuracy: 0.8936 - val_loss: 0.5774 - val_accuracy: 0.8443\n",
      "Epoch 751/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2447 - accuracy: 0.8939 - val_loss: 0.6051 - val_accuracy: 0.8344\n",
      "Epoch 752/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.8905 - val_loss: 0.5776 - val_accuracy: 0.8480\n",
      "Epoch 753/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2436 - accuracy: 0.8939 - val_loss: 0.5915 - val_accuracy: 0.8368\n",
      "Epoch 754/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2507 - accuracy: 0.8936 - val_loss: 0.5638 - val_accuracy: 0.8467\n",
      "Epoch 755/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2516 - accuracy: 0.8911 - val_loss: 0.5242 - val_accuracy: 0.8504\n",
      "Epoch 756/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2418 - accuracy: 0.8929 - val_loss: 0.5702 - val_accuracy: 0.8455\n",
      "Epoch 757/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2534 - accuracy: 0.8899 - val_loss: 0.5927 - val_accuracy: 0.8381\n",
      "Epoch 758/1000\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.2478 - accuracy: 0.8923 - val_loss: 0.5777 - val_accuracy: 0.8356\n",
      "Epoch 759/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2475 - accuracy: 0.8905 - val_loss: 0.5723 - val_accuracy: 0.8405\n",
      "Epoch 760/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2408 - accuracy: 0.8967 - val_loss: 0.6072 - val_accuracy: 0.8331\n",
      "Epoch 761/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2471 - accuracy: 0.8880 - val_loss: 0.5899 - val_accuracy: 0.8381\n",
      "Epoch 762/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2386 - accuracy: 0.8933 - val_loss: 0.5537 - val_accuracy: 0.8381\n",
      "Epoch 763/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2289 - accuracy: 0.9007 - val_loss: 0.5883 - val_accuracy: 0.8430\n",
      "Epoch 764/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2339 - accuracy: 0.8967 - val_loss: 0.6263 - val_accuracy: 0.8443\n",
      "Epoch 765/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2398 - accuracy: 0.8982 - val_loss: 0.5518 - val_accuracy: 0.8405\n",
      "Epoch 766/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2361 - accuracy: 0.8936 - val_loss: 0.5953 - val_accuracy: 0.8381\n",
      "Epoch 767/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2389 - accuracy: 0.8982 - val_loss: 0.5741 - val_accuracy: 0.8282\n",
      "Epoch 768/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2451 - accuracy: 0.8942 - val_loss: 0.5669 - val_accuracy: 0.8443\n",
      "Epoch 769/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2413 - accuracy: 0.8905 - val_loss: 0.5758 - val_accuracy: 0.8368\n",
      "Epoch 770/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2385 - accuracy: 0.8963 - val_loss: 0.5529 - val_accuracy: 0.8418\n",
      "Epoch 771/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2363 - accuracy: 0.8914 - val_loss: 0.6006 - val_accuracy: 0.8344\n",
      "Epoch 772/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2508 - accuracy: 0.8908 - val_loss: 0.6106 - val_accuracy: 0.8319\n",
      "Epoch 773/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2595 - accuracy: 0.8902 - val_loss: 0.5807 - val_accuracy: 0.8405\n",
      "Epoch 774/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2404 - accuracy: 0.8985 - val_loss: 0.6139 - val_accuracy: 0.8331\n",
      "Epoch 775/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2371 - accuracy: 0.8957 - val_loss: 0.5623 - val_accuracy: 0.8393\n",
      "Epoch 776/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2390 - accuracy: 0.8954 - val_loss: 0.5714 - val_accuracy: 0.8319\n",
      "Epoch 777/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2594 - accuracy: 0.8840 - val_loss: 0.5864 - val_accuracy: 0.8430\n",
      "Epoch 778/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2346 - accuracy: 0.8988 - val_loss: 0.6043 - val_accuracy: 0.8368\n",
      "Epoch 779/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2426 - accuracy: 0.8936 - val_loss: 0.5655 - val_accuracy: 0.8430\n",
      "Epoch 780/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2252 - accuracy: 0.9004 - val_loss: 0.5711 - val_accuracy: 0.8344\n",
      "Epoch 781/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2380 - accuracy: 0.8963 - val_loss: 0.6177 - val_accuracy: 0.8331\n",
      "Epoch 782/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2432 - accuracy: 0.8914 - val_loss: 0.5720 - val_accuracy: 0.8405\n",
      "Epoch 783/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2411 - accuracy: 0.8957 - val_loss: 0.5736 - val_accuracy: 0.8344\n",
      "Epoch 784/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2407 - accuracy: 0.8960 - val_loss: 0.6021 - val_accuracy: 0.8381\n",
      "Epoch 785/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2450 - accuracy: 0.8926 - val_loss: 0.5853 - val_accuracy: 0.8443\n",
      "Epoch 786/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2641 - accuracy: 0.8877 - val_loss: 0.6123 - val_accuracy: 0.8356\n",
      "Epoch 787/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.8874 - val_loss: 0.6157 - val_accuracy: 0.8405\n",
      "Epoch 788/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2425 - accuracy: 0.8929 - val_loss: 0.6033 - val_accuracy: 0.8319\n",
      "Epoch 789/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2523 - accuracy: 0.8902 - val_loss: 0.6023 - val_accuracy: 0.8344\n",
      "Epoch 790/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.8967 - val_loss: 0.6614 - val_accuracy: 0.8282\n",
      "Epoch 791/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2379 - accuracy: 0.8976 - val_loss: 0.5620 - val_accuracy: 0.8418\n",
      "Epoch 792/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2342 - accuracy: 0.8936 - val_loss: 0.5868 - val_accuracy: 0.8467\n",
      "Epoch 793/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2550 - accuracy: 0.8883 - val_loss: 0.5573 - val_accuracy: 0.8405\n",
      "Epoch 794/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2616 - accuracy: 0.8871 - val_loss: 0.5962 - val_accuracy: 0.8393\n",
      "Epoch 795/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2323 - accuracy: 0.8970 - val_loss: 0.5949 - val_accuracy: 0.8381\n",
      "Epoch 796/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2383 - accuracy: 0.8933 - val_loss: 0.5976 - val_accuracy: 0.8418\n",
      "Epoch 797/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2290 - accuracy: 0.9032 - val_loss: 0.5921 - val_accuracy: 0.8443\n",
      "Epoch 798/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9001 - val_loss: 0.6160 - val_accuracy: 0.8331\n",
      "Epoch 799/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2441 - accuracy: 0.8948 - val_loss: 0.5536 - val_accuracy: 0.8368\n",
      "Epoch 800/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2451 - accuracy: 0.8933 - val_loss: 0.5795 - val_accuracy: 0.8492\n",
      "Epoch 801/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2374 - accuracy: 0.8976 - val_loss: 0.5730 - val_accuracy: 0.8331\n",
      "Epoch 802/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2449 - accuracy: 0.8929 - val_loss: 0.5701 - val_accuracy: 0.8405\n",
      "Epoch 803/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2413 - accuracy: 0.8920 - val_loss: 0.5886 - val_accuracy: 0.8455\n",
      "Epoch 804/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2602 - accuracy: 0.8868 - val_loss: 0.5738 - val_accuracy: 0.8393\n",
      "Epoch 805/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.8923 - val_loss: 0.5557 - val_accuracy: 0.8418\n",
      "Epoch 806/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2304 - accuracy: 0.8985 - val_loss: 0.5585 - val_accuracy: 0.8405\n",
      "Epoch 807/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2310 - accuracy: 0.9025 - val_loss: 0.5979 - val_accuracy: 0.8418\n",
      "Epoch 808/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.8886 - val_loss: 0.5584 - val_accuracy: 0.8381\n",
      "Epoch 809/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2426 - accuracy: 0.8954 - val_loss: 0.5848 - val_accuracy: 0.8319\n",
      "Epoch 810/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2485 - accuracy: 0.8933 - val_loss: 0.5861 - val_accuracy: 0.8443\n",
      "Epoch 811/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2489 - accuracy: 0.8914 - val_loss: 0.5972 - val_accuracy: 0.8418\n",
      "Epoch 812/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2407 - accuracy: 0.8917 - val_loss: 0.5963 - val_accuracy: 0.8430\n",
      "Epoch 813/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2447 - accuracy: 0.8908 - val_loss: 0.5612 - val_accuracy: 0.8467\n",
      "Epoch 814/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2306 - accuracy: 0.9004 - val_loss: 0.5837 - val_accuracy: 0.8368\n",
      "Epoch 815/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2272 - accuracy: 0.9010 - val_loss: 0.5651 - val_accuracy: 0.8319\n",
      "Epoch 816/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2482 - accuracy: 0.8877 - val_loss: 0.5994 - val_accuracy: 0.8418\n",
      "Epoch 817/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2286 - accuracy: 0.8991 - val_loss: 0.5635 - val_accuracy: 0.8405\n",
      "Epoch 818/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2351 - accuracy: 0.8942 - val_loss: 0.5834 - val_accuracy: 0.8356\n",
      "Epoch 819/1000\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 0.2361 - accuracy: 0.8991 - val_loss: 0.6212 - val_accuracy: 0.8381\n",
      "Epoch 820/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2312 - accuracy: 0.8970 - val_loss: 0.5588 - val_accuracy: 0.8504\n",
      "Epoch 821/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2444 - accuracy: 0.8933 - val_loss: 0.5765 - val_accuracy: 0.8381\n",
      "Epoch 822/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2293 - accuracy: 0.8963 - val_loss: 0.5677 - val_accuracy: 0.8393\n",
      "Epoch 823/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2512 - accuracy: 0.8929 - val_loss: 0.6453 - val_accuracy: 0.8319\n",
      "Epoch 824/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.8899 - val_loss: 0.6050 - val_accuracy: 0.8443\n",
      "Epoch 825/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.8976 - val_loss: 0.5799 - val_accuracy: 0.8405\n",
      "Epoch 826/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2260 - accuracy: 0.9004 - val_loss: 0.6171 - val_accuracy: 0.8381\n",
      "Epoch 827/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2357 - accuracy: 0.8979 - val_loss: 0.5718 - val_accuracy: 0.8480\n",
      "Epoch 828/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2457 - accuracy: 0.8883 - val_loss: 0.5751 - val_accuracy: 0.8504\n",
      "Epoch 829/1000\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.2231 - accuracy: 0.8994 - val_loss: 0.5949 - val_accuracy: 0.8405\n",
      "Epoch 830/1000\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.2197 - accuracy: 0.9041 - val_loss: 0.5660 - val_accuracy: 0.8467\n",
      "Epoch 831/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9056 - val_loss: 0.6063 - val_accuracy: 0.8405\n",
      "Epoch 832/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 0.5904 - val_accuracy: 0.8455\n",
      "Epoch 833/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9001 - val_loss: 0.5792 - val_accuracy: 0.8331\n",
      "Epoch 834/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.8960 - val_loss: 0.6416 - val_accuracy: 0.8381\n",
      "Epoch 835/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8861 - val_loss: 0.5854 - val_accuracy: 0.8443\n",
      "Epoch 836/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8895 - val_loss: 0.6061 - val_accuracy: 0.8418\n",
      "Epoch 837/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8920 - val_loss: 0.5891 - val_accuracy: 0.8405\n",
      "Epoch 838/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.8963 - val_loss: 0.5703 - val_accuracy: 0.8480\n",
      "Epoch 839/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.8942 - val_loss: 0.5517 - val_accuracy: 0.8430\n",
      "Epoch 840/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9041 - val_loss: 0.6055 - val_accuracy: 0.8344\n",
      "Epoch 841/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9038 - val_loss: 0.5486 - val_accuracy: 0.8405\n",
      "Epoch 842/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.8892 - val_loss: 0.6373 - val_accuracy: 0.8430\n",
      "Epoch 843/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8728 - val_loss: 0.6188 - val_accuracy: 0.8245\n",
      "Epoch 844/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8803 - val_loss: 0.5143 - val_accuracy: 0.8443\n",
      "Epoch 845/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.8923 - val_loss: 0.5640 - val_accuracy: 0.8381\n",
      "Epoch 846/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.8973 - val_loss: 0.6153 - val_accuracy: 0.8430\n",
      "Epoch 847/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.8926 - val_loss: 0.5740 - val_accuracy: 0.8393\n",
      "Epoch 848/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.8982 - val_loss: 0.5536 - val_accuracy: 0.8443\n",
      "Epoch 849/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.8960 - val_loss: 0.5882 - val_accuracy: 0.8443\n",
      "Epoch 850/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.8954 - val_loss: 0.5654 - val_accuracy: 0.8517\n",
      "Epoch 851/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9001 - val_loss: 0.6097 - val_accuracy: 0.8344\n",
      "Epoch 852/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.8948 - val_loss: 0.6497 - val_accuracy: 0.8356\n",
      "Epoch 853/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.8936 - val_loss: 0.5646 - val_accuracy: 0.8418\n",
      "Epoch 854/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9025 - val_loss: 0.6054 - val_accuracy: 0.8405\n",
      "Epoch 855/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.8945 - val_loss: 0.5935 - val_accuracy: 0.8282\n",
      "Epoch 856/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.8880 - val_loss: 0.5717 - val_accuracy: 0.8504\n",
      "Epoch 857/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9010 - val_loss: 0.5798 - val_accuracy: 0.8443\n",
      "Epoch 858/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9035 - val_loss: 0.6235 - val_accuracy: 0.8381\n",
      "Epoch 859/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.8994 - val_loss: 0.6056 - val_accuracy: 0.8381\n",
      "Epoch 860/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2377 - accuracy: 0.8905 - val_loss: 0.6004 - val_accuracy: 0.8393\n",
      "Epoch 861/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.8923 - val_loss: 0.6029 - val_accuracy: 0.8443\n",
      "Epoch 862/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.8939 - val_loss: 0.5885 - val_accuracy: 0.8430\n",
      "Epoch 863/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.8923 - val_loss: 0.6313 - val_accuracy: 0.8356\n",
      "Epoch 864/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8601 - val_loss: 0.5764 - val_accuracy: 0.8294\n",
      "Epoch 865/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8654 - val_loss: 0.5445 - val_accuracy: 0.8368\n",
      "Epoch 866/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2795 - accuracy: 0.8818 - val_loss: 0.5675 - val_accuracy: 0.8331\n",
      "Epoch 867/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.8874 - val_loss: 0.5831 - val_accuracy: 0.8381\n",
      "Epoch 868/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.8908 - val_loss: 0.5668 - val_accuracy: 0.8393\n",
      "Epoch 869/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.8905 - val_loss: 0.5733 - val_accuracy: 0.8356\n",
      "Epoch 870/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2361 - accuracy: 0.8942 - val_loss: 0.5839 - val_accuracy: 0.8356\n",
      "Epoch 871/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.8988 - val_loss: 0.6039 - val_accuracy: 0.8356\n",
      "Epoch 872/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.8973 - val_loss: 0.5462 - val_accuracy: 0.8418\n",
      "Epoch 873/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2265 - accuracy: 0.9022 - val_loss: 0.5981 - val_accuracy: 0.8393\n",
      "Epoch 874/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2277 - accuracy: 0.8973 - val_loss: 0.5903 - val_accuracy: 0.8294\n",
      "Epoch 875/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2289 - accuracy: 0.9007 - val_loss: 0.5592 - val_accuracy: 0.8418\n",
      "Epoch 876/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2193 - accuracy: 0.9035 - val_loss: 0.6002 - val_accuracy: 0.8443\n",
      "Epoch 877/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9016 - val_loss: 0.6126 - val_accuracy: 0.8368\n",
      "Epoch 878/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8960 - val_loss: 0.6096 - val_accuracy: 0.8418\n",
      "Epoch 879/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.8988 - val_loss: 0.6271 - val_accuracy: 0.8319\n",
      "Epoch 880/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.8948 - val_loss: 0.5524 - val_accuracy: 0.8455\n",
      "Epoch 881/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.9059 - val_loss: 0.5722 - val_accuracy: 0.8467\n",
      "Epoch 882/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.8954 - val_loss: 0.6245 - val_accuracy: 0.8368\n",
      "Epoch 883/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.8945 - val_loss: 0.6075 - val_accuracy: 0.8368\n",
      "Epoch 884/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.8976 - val_loss: 0.6006 - val_accuracy: 0.8393\n",
      "Epoch 885/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9007 - val_loss: 0.5917 - val_accuracy: 0.8455\n",
      "Epoch 886/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.8929 - val_loss: 0.5838 - val_accuracy: 0.8455\n",
      "Epoch 887/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9007 - val_loss: 0.5753 - val_accuracy: 0.8443\n",
      "Epoch 888/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.8957 - val_loss: 0.6031 - val_accuracy: 0.8443\n",
      "Epoch 889/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.8985 - val_loss: 0.6138 - val_accuracy: 0.8455\n",
      "Epoch 890/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2228 - accuracy: 0.9041 - val_loss: 0.5835 - val_accuracy: 0.8418\n",
      "Epoch 891/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.8994 - val_loss: 0.6668 - val_accuracy: 0.8393\n",
      "Epoch 892/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9053 - val_loss: 0.5707 - val_accuracy: 0.8480\n",
      "Epoch 893/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9013 - val_loss: 0.6174 - val_accuracy: 0.8344\n",
      "Epoch 894/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2308 - accuracy: 0.8960 - val_loss: 0.6172 - val_accuracy: 0.8319\n",
      "Epoch 895/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.8991 - val_loss: 0.6173 - val_accuracy: 0.8368\n",
      "Epoch 896/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.8920 - val_loss: 0.6739 - val_accuracy: 0.8356\n",
      "Epoch 897/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8855 - val_loss: 0.6182 - val_accuracy: 0.8381\n",
      "Epoch 898/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8902 - val_loss: 0.5947 - val_accuracy: 0.8356\n",
      "Epoch 899/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9066 - val_loss: 0.5895 - val_accuracy: 0.8331\n",
      "Epoch 900/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.8914 - val_loss: 0.5935 - val_accuracy: 0.8492\n",
      "Epoch 901/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.8970 - val_loss: 0.5870 - val_accuracy: 0.8430\n",
      "Epoch 902/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9010 - val_loss: 0.5948 - val_accuracy: 0.8455\n",
      "Epoch 903/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9016 - val_loss: 0.5960 - val_accuracy: 0.8393\n",
      "Epoch 904/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.8899 - val_loss: 0.6158 - val_accuracy: 0.8455\n",
      "Epoch 905/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.8982 - val_loss: 0.6301 - val_accuracy: 0.8368\n",
      "Epoch 906/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.8973 - val_loss: 0.6041 - val_accuracy: 0.8443\n",
      "Epoch 907/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.8998 - val_loss: 0.5664 - val_accuracy: 0.8455\n",
      "Epoch 908/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.8883 - val_loss: 0.5918 - val_accuracy: 0.8307\n",
      "Epoch 909/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.8920 - val_loss: 0.6078 - val_accuracy: 0.8344\n",
      "Epoch 910/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.8911 - val_loss: 0.5561 - val_accuracy: 0.8455\n",
      "Epoch 911/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9019 - val_loss: 0.6294 - val_accuracy: 0.8381\n",
      "Epoch 912/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9035 - val_loss: 0.5669 - val_accuracy: 0.8418\n",
      "Epoch 913/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2231 - accuracy: 0.8998 - val_loss: 0.5829 - val_accuracy: 0.8405\n",
      "Epoch 914/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9025 - val_loss: 0.6634 - val_accuracy: 0.8319\n",
      "Epoch 915/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.8970 - val_loss: 0.6173 - val_accuracy: 0.8381\n",
      "Epoch 916/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2180 - accuracy: 0.9028 - val_loss: 0.6064 - val_accuracy: 0.8393\n",
      "Epoch 917/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9001 - val_loss: 0.6153 - val_accuracy: 0.8368\n",
      "Epoch 918/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.8923 - val_loss: 0.6451 - val_accuracy: 0.8307\n",
      "Epoch 919/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2278 - accuracy: 0.8998 - val_loss: 0.6708 - val_accuracy: 0.8220\n",
      "Epoch 920/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9075 - val_loss: 0.5947 - val_accuracy: 0.8405\n",
      "Epoch 921/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2263 - accuracy: 0.8982 - val_loss: 0.6422 - val_accuracy: 0.8418\n",
      "Epoch 922/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.8948 - val_loss: 0.6070 - val_accuracy: 0.8480\n",
      "Epoch 923/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.8926 - val_loss: 0.6466 - val_accuracy: 0.8307\n",
      "Epoch 924/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.8880 - val_loss: 0.6106 - val_accuracy: 0.8344\n",
      "Epoch 925/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.8970 - val_loss: 0.6258 - val_accuracy: 0.8307\n",
      "Epoch 926/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9004 - val_loss: 0.6045 - val_accuracy: 0.8504\n",
      "Epoch 927/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.8979 - val_loss: 0.6590 - val_accuracy: 0.8356\n",
      "Epoch 928/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8685 - val_loss: 0.6005 - val_accuracy: 0.8455\n",
      "Epoch 929/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8852 - val_loss: 0.6231 - val_accuracy: 0.8208\n",
      "Epoch 930/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8963 - val_loss: 0.6073 - val_accuracy: 0.8331\n",
      "Epoch 931/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2382 - accuracy: 0.8988 - val_loss: 0.6201 - val_accuracy: 0.8405\n",
      "Epoch 932/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.8982 - val_loss: 0.6381 - val_accuracy: 0.8319\n",
      "Epoch 933/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.9013 - val_loss: 0.6350 - val_accuracy: 0.8381\n",
      "Epoch 934/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9025 - val_loss: 0.5887 - val_accuracy: 0.8319\n",
      "Epoch 935/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9007 - val_loss: 0.6172 - val_accuracy: 0.8368\n",
      "Epoch 936/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9007 - val_loss: 0.6438 - val_accuracy: 0.8307\n",
      "Epoch 937/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.8963 - val_loss: 0.6238 - val_accuracy: 0.8405\n",
      "Epoch 938/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.8948 - val_loss: 0.6359 - val_accuracy: 0.8344\n",
      "Epoch 939/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2242 - accuracy: 0.9041 - val_loss: 0.6520 - val_accuracy: 0.8307\n",
      "Epoch 940/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8917 - val_loss: 0.6687 - val_accuracy: 0.8232\n",
      "Epoch 941/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8902 - val_loss: 0.6405 - val_accuracy: 0.8331\n",
      "Epoch 942/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8970 - val_loss: 0.6120 - val_accuracy: 0.8344\n",
      "Epoch 943/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9013 - val_loss: 0.6687 - val_accuracy: 0.8319\n",
      "Epoch 944/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9032 - val_loss: 0.6095 - val_accuracy: 0.8344\n",
      "Epoch 945/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.8976 - val_loss: 0.6033 - val_accuracy: 0.8430\n",
      "Epoch 946/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.8954 - val_loss: 0.6217 - val_accuracy: 0.8331\n",
      "Epoch 947/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.8991 - val_loss: 0.6183 - val_accuracy: 0.8393\n",
      "Epoch 948/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.9056 - val_loss: 0.6452 - val_accuracy: 0.8319\n",
      "Epoch 949/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9038 - val_loss: 0.6345 - val_accuracy: 0.8269\n",
      "Epoch 950/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8877 - val_loss: 0.6323 - val_accuracy: 0.8467\n",
      "Epoch 951/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8905 - val_loss: 0.6281 - val_accuracy: 0.8331\n",
      "Epoch 952/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.8920 - val_loss: 0.5891 - val_accuracy: 0.8344\n",
      "Epoch 953/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8942 - val_loss: 0.6425 - val_accuracy: 0.8319\n",
      "Epoch 954/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8880 - val_loss: 0.5583 - val_accuracy: 0.8356\n",
      "Epoch 955/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.8939 - val_loss: 0.6142 - val_accuracy: 0.8393\n",
      "Epoch 956/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9004 - val_loss: 0.5944 - val_accuracy: 0.8393\n",
      "Epoch 957/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.8908 - val_loss: 0.5893 - val_accuracy: 0.8344\n",
      "Epoch 958/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.8973 - val_loss: 0.6112 - val_accuracy: 0.8418\n",
      "Epoch 959/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8960 - val_loss: 0.5864 - val_accuracy: 0.8418\n",
      "Epoch 960/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9010 - val_loss: 0.6335 - val_accuracy: 0.8307\n",
      "Epoch 961/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.8994 - val_loss: 0.6253 - val_accuracy: 0.8418\n",
      "Epoch 962/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.8951 - val_loss: 0.6375 - val_accuracy: 0.8381\n",
      "Epoch 963/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.9022 - val_loss: 0.6327 - val_accuracy: 0.8282\n",
      "Epoch 964/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9044 - val_loss: 0.6131 - val_accuracy: 0.8381\n",
      "Epoch 965/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.9004 - val_loss: 0.5891 - val_accuracy: 0.8405\n",
      "Epoch 966/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.8979 - val_loss: 0.6529 - val_accuracy: 0.8294\n",
      "Epoch 967/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.8951 - val_loss: 0.5893 - val_accuracy: 0.8381\n",
      "Epoch 968/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2334 - accuracy: 0.8979 - val_loss: 0.6269 - val_accuracy: 0.8405\n",
      "Epoch 969/1000\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 0.2222 - accuracy: 0.9004 - val_loss: 0.5971 - val_accuracy: 0.8430\n",
      "Epoch 970/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2277 - accuracy: 0.8979 - val_loss: 0.6889 - val_accuracy: 0.8257\n",
      "Epoch 971/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2422 - accuracy: 0.8923 - val_loss: 0.6477 - val_accuracy: 0.8294\n",
      "Epoch 972/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.8970 - val_loss: 0.6572 - val_accuracy: 0.8405\n",
      "Epoch 973/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2390 - accuracy: 0.8948 - val_loss: 0.6407 - val_accuracy: 0.8294\n",
      "Epoch 974/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2265 - accuracy: 0.9019 - val_loss: 0.6202 - val_accuracy: 0.8393\n",
      "Epoch 975/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.8948 - val_loss: 0.6370 - val_accuracy: 0.8430\n",
      "Epoch 976/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.8988 - val_loss: 0.5974 - val_accuracy: 0.8443\n",
      "Epoch 977/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2320 - accuracy: 0.8991 - val_loss: 0.5857 - val_accuracy: 0.8430\n",
      "Epoch 978/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8911 - val_loss: 0.7166 - val_accuracy: 0.8393\n",
      "Epoch 979/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8762 - val_loss: 0.6025 - val_accuracy: 0.8368\n",
      "Epoch 980/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.8899 - val_loss: 0.6005 - val_accuracy: 0.8307\n",
      "Epoch 981/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.8861 - val_loss: 0.6265 - val_accuracy: 0.8368\n",
      "Epoch 982/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2261 - accuracy: 0.9019 - val_loss: 0.5804 - val_accuracy: 0.8430\n",
      "Epoch 983/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9050 - val_loss: 0.6339 - val_accuracy: 0.8257\n",
      "Epoch 984/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9075 - val_loss: 0.7066 - val_accuracy: 0.8331\n",
      "Epoch 985/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.8976 - val_loss: 0.6446 - val_accuracy: 0.8344\n",
      "Epoch 986/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.8973 - val_loss: 0.6451 - val_accuracy: 0.8331\n",
      "Epoch 987/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.8963 - val_loss: 0.6154 - val_accuracy: 0.8331\n",
      "Epoch 988/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9007 - val_loss: 0.6767 - val_accuracy: 0.8319\n",
      "Epoch 989/1000\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.8942 - val_loss: 0.6634 - val_accuracy: 0.8344\n",
      "Epoch 990/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9044 - val_loss: 0.6205 - val_accuracy: 0.8405\n",
      "Epoch 991/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9032 - val_loss: 0.6336 - val_accuracy: 0.8368\n",
      "Epoch 992/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.8976 - val_loss: 0.7126 - val_accuracy: 0.8282\n",
      "Epoch 993/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2388 - accuracy: 0.8988 - val_loss: 0.6084 - val_accuracy: 0.8393\n",
      "Epoch 994/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.8923 - val_loss: 0.6195 - val_accuracy: 0.8430\n",
      "Epoch 995/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.8973 - val_loss: 0.6078 - val_accuracy: 0.8368\n",
      "Epoch 996/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9062 - val_loss: 0.6198 - val_accuracy: 0.8418\n",
      "Epoch 997/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.8963 - val_loss: 0.6149 - val_accuracy: 0.8393\n",
      "Epoch 998/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9013 - val_loss: 0.6102 - val_accuracy: 0.8381\n",
      "Epoch 999/1000\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.8973 - val_loss: 0.6316 - val_accuracy: 0.8368\n",
      "Epoch 1000/1000\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.8976 - val_loss: 0.6728 - val_accuracy: 0.8331\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x16731561220>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, validation_split=0.2, epochs=1000, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model.save('ColorModel.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8872\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.3128422796726227, 0.8871566653251648]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xTrain, yTrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.8546\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6966720819473267, 0.8545994162559509]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xTest, yTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1152x864 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testPredictions = model.predict(xTest)\n",
    "testPredictions = np.argmax(testPredictions, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusionMatrix = confusion_matrix(yTest, testPredictions)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "f,ax = plt.subplots(figsize=(16,12))\n",
    "categories = ['Red', 'Green', 'Blue', 'Yellow', 'Orange', 'Pink', 'Purple', 'Brown', 'Grey', 'Black', 'White']\n",
    "sns.heatmap(confusionMatrix, annot=True, cmap='Blues', fmt='d', xticklabels = categories, yticklabels = categories)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}